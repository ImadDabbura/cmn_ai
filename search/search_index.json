{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"cmn_ai","text":"<p>A high-performance machine learning library for accelerating AI, Deep Learning, and Data Science workflows</p> <p> </p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>cmn_ai is a comprehensive Python machine learning library designed to accelerate AI, Deep Learning, and Data Science workflows. Built from extensive real-world experience, it provides robust, reusable components for PyTorch-based deep learning and scikit-learn compatible tabular data processing.</p> <p>The library follows Boyd's Law \u2014 speed of iteration beats quality of iteration \u2014 enabling rapid experimentation and faster delivery of machine learning solutions.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#accelerated-development","title":"\ud83d\ude80 Accelerated Development","text":"<ul> <li>Pre-built modules eliminate boilerplate code</li> <li>Flexible callback system for training customization</li> <li>Seamless integration with existing workflows</li> </ul>"},{"location":"#best-practices-built-in","title":"\ud83c\udfaf Best Practices Built-In","text":"<ul> <li>Years of ML engineering experience distilled into reusable components</li> <li>Robust error handling and memory management</li> <li>Consistent APIs across all modules</li> </ul>"},{"location":"#framework-integration","title":"\ud83d\udd27 Framework Integration","text":"<ul> <li>Deep Learning: Built on PyTorch with flexible <code>Learner</code> architecture</li> <li>Tabular ML: Full scikit-learn <code>Pipeline</code> and <code>ColumnTransformer</code> compatibility</li> <li>Visualization: Integrated plotting utilities for models and data</li> </ul>"},{"location":"#domain-specific-tools","title":"\ud83d\udcca Domain-Specific Tools","text":"<ul> <li>Vision: Computer vision utilities with <code>VisionLearner</code> and batch visualization</li> <li>Text: NLP preprocessing and dataset handling with <code>TextList</code></li> <li>Tabular: EDA tools and scikit-learn compatible transformers</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-pypi-recommended","title":"From PyPI (Recommended)","text":"<pre><code>pip install cmn-ai\n</code></pre>"},{"location":"#development-installation","title":"Development Installation","text":"<pre><code>git clone https://github.com/ImadDabbura/cmn_ai.git\ncd cmn_ai\npip install poetry\npoetry install\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#deep-learning-with-learner","title":"Deep Learning with Learner","text":"<pre><code>from cmn_ai.learner import Learner\nfrom cmn_ai.callbacks.training import DeviceCallBack, Recorder\n\n# Create a learner with callbacks\nlearner = Learner(model, dls, loss_func, opt_func, callbacks=[Recorder(\"lr\")])\nlearner.add_callback(DeviceCallBack(\"cuda:0\"))\n\n# Train your model\nlearner.fit(epochs=10, lr=1e-3)\n</code></pre>"},{"location":"#vision-tasks","title":"Vision Tasks","text":"<pre><code>from cmn_ai.vision import VisionLearner\n\n# Vision-specific learner with built-in utilities\nvision_learner = VisionLearner(model, dls, loss_func)\nvision_learner.show_batch()  # Visualize training data\nvision_learner.fit(epochs=20, lr=1e-4)\n</code></pre>"},{"location":"#tabular-data-processing","title":"Tabular Data Processing","text":"<pre><code>import pandas as pd\nfrom cmn_ai.tabular.preprocessing import DateTransformer\nfrom sklearn.pipeline import Pipeline\n\n# Scikit-learn compatible preprocessing\nx = pd.DataFrame(\n    pd.date_range(start=pd.to_datetime(\"1/1/2018\"), end=pd.to_datetime(\"1/08/2018\"))\n)\ntfm = DateTransformer(drop=False)\ntfm.fit_transform(X_train, y_train)\n</code></pre>"},{"location":"#core-architecture","title":"Core Architecture","text":""},{"location":"#learner-system","title":"Learner System","text":"<p>The <code>Learner</code> class provides a flexible foundation for training deep learning models with:</p> <ul> <li>Exception-based callback system for fine-grained training control</li> <li>Automatic mixed precision support</li> <li>Built-in logging and metrics tracking</li> <li>Memory optimization utilities</li> </ul>"},{"location":"#callback-framework","title":"Callback Framework","text":"<p>Fine-grained training control through exception-based callbacks:</p> <ul> <li><code>CancelBatchException</code>: Skip current batch</li> <li><code>CancelStepException</code>: Skip optimizer step</li> <li><code>CancelBackwardException</code>: Skip backward pass</li> <li><code>CancelEpochException</code>: Skip current epoch</li> <li><code>CancelFitException</code>: Stop training entirely</li> </ul>"},{"location":"#modular-design","title":"Modular Design","text":"<pre><code>cmn_ai/\n\u251c\u2500\u2500 learner.py          # Core Learner class\n\u251c\u2500\u2500 callbacks/          # Training callbacks\n\u251c\u2500\u2500 vision/            # Computer vision utilities\n\u251c\u2500\u2500 text/              # NLP processing tools\n\u251c\u2500\u2500 tabular/           # Traditional ML tools\n\u251c\u2500\u2500 utils/             # Core utilities\n\u251c\u2500\u2500 plot.py            # Visualization tools\n\u2514\u2500\u2500 losses.py          # Custom loss functions\n</code></pre>"},{"location":"#examples","title":"Examples","text":""},{"location":"#training-loop-customization","title":"Training Loop Customization","text":"<pre><code>from functools import partial\nfrom cmn_ai.callbacks.schedule import BatchScheduler\nfrom cmn_ai.callbacks.training import MetricsCallback, ProgressCallback\nfrom torcheval.metrics import MulticlassAccuracy\nimport torch.optim as opt\n\nsched = partial(opt.lr_scheduler.OneCycleLR, max_lr=6e-2, total_steps=100)\nlearner = Learner(model, dls, loss_func, opt_func)\nlearner.add_callbacks(\n    [\n        ProgressCallback(),\n        BatchScheduler(sched),\n        MetricsCallback(accuracy=MulticlassAccuracy(nm_classes=10)),\n    ]\n)\n\nlearner.fit(epochs=50, lr=1e-3)\n</code></pre>"},{"location":"#custom-callback-creation","title":"Custom Callback Creation","text":"<pre><code>from cmn_ai.callbacks import Callback\n\n\nclass CustomCallback(Callback):\n    def after_batch(self):\n        if self.loss &lt; self.threshold:\n            print(f\"Threshold reached at batch {self.batch}\")\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>\ud83d\udcd6 Full Documentation</p> <p>TODO:</p> <ul> <li>[ ][API Reference](https://imaddabbura.github.io/cmn_ai/api/)</li> <li>[ ][Tutorial Notebooks](https://imaddabbura.github.io/cmn_ai/tutorials/)</li> <li>[ ][Advanced Usage](https://imaddabbura.github.io/cmn_ai/advanced/)</li> </ul>"},{"location":"#development","title":"Development","text":""},{"location":"#setup-development-environment","title":"Setup Development Environment","text":"<pre><code>git clone https://github.com/ImadDabbura/cmn_ai.git\ncd cmn_ai\npoetry install\n</code></pre>"},{"location":"#run-tests","title":"Run Tests","text":"<pre><code># Full test suite\npoetry run pytest\n\n# With coverage\npoetry run pytest --cov=cmn_ai\n\n# Specific test file\npoetry run pytest tests/test_learner.py\n</code></pre>"},{"location":"#code-quality","title":"Code Quality","text":"<pre><code># pre-commit will take care of all things formatting, linting, syntax errors,\n# tests, etc.\npre-commit run --all-files\n</code></pre>"},{"location":"#build-documentation","title":"Build Documentation","text":"<pre><code>mkdocs serve    # Local development server\nmkdocs build    # Build documentation\n</code></pre>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python: 3.13+</li> <li>Core Dependencies: PyTorch, scikit-learn, NumPy, pandas</li> <li>Optional: matplotlib, seaborn (for plotting)</li> </ul>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li>[ ] Distributed training support</li> <li>[ ] Additional vision architectures</li> <li>[ ] Advanced NLP utilities</li> <li>[ ] AutoML capabilities</li> <li>[ ] Model deployment tools</li> </ul>"},{"location":"#contributing","title":"\ud83d\ude4c Contributing","text":"<p>Contributions are what make the open-source community such an amazing place to learn, inspire, and create. Any contributions you make are greatly appreciated.</p> <p>If you have suggestions for adding or removing projects, please fork the repo, make your changes, and create a pull request. You can also simply open an issue with the tag \"enhancement\".</p> <p>Stay tuned for contribution guidelines!</p>"},{"location":"#license","title":"License","text":"<p>Licensed under the Apache License 2.0.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use cmn_ai in your research, please cite:</p> <pre><code>@software{cmn_ai,\n  title={cmn_ai: A Machine Learning Library for Accelerated AI Workflows},\n  author={Imad Dabbura},\n  url={https://github.com/ImadDabbura/cmn_ai},\n  year={2024}\n}\n</code></pre> Built with \u2764\ufe0f for the ML community"},{"location":"activations/","title":"Activations","text":"<p>Activation functions for neural networks.</p> <p>This module provides custom activation functions that extend the standard PyTorch activation functions with additional functionality and flexibility.</p> <p>Classes:</p> <ul> <li> <code>GeneralRelu : nn.Module</code>           \u2013            <p>A generalized Rectified Linear Unit with configurable leaky slope, output subtraction, and maximum value clipping.</p> </li> </ul> Notes <p>All activation functions in this module are designed to be compatible with PyTorch's nn.Module interface and can be used as drop-in replacements for standard activation functions in neural network architectures.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from cmn_ai.activations import GeneralRelu\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a generalized ReLU with custom parameters\n&gt;&gt;&gt; act = GeneralRelu(leak=0.1, sub=0.4, maxv=6.0)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Apply to input tensor\n&gt;&gt;&gt; x = torch.tensor([-2.0, -0.5, 0.5, 2.0])\n&gt;&gt;&gt; output = act(x)\n&gt;&gt;&gt; print(output)\ntensor([-0.6000, -0.4500,  0.1000,  1.6000])\n</code></pre>"},{"location":"activations/#cmn_ai.activations.GeneralRelu","title":"<code>GeneralRelu</code>","text":"<p>               Bases: <code>Module</code></p> <p>A generalized Rectified Linear Unit (ReLU) activation function with optional leaky slope, output subtraction, and maximum value clipping.</p> <p>Parameters:</p> <ul> <li> <code>leak</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>Negative slope for values less than zero, similar to LeakyReLU. If None (default), standard ReLU behavior is used (all negatives set to 0).</p> </li> <li> <code>sub</code>               (<code>float</code>, default:                   <code>0.4</code> )           \u2013            <p>A constant value to subtract from the activation output after applying ReLU/LeakyReLU. If None (default), no subtraction is applied.</p> </li> <li> <code>maxv</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>Maximum value to clip the activation output to. If None (default), no clipping is applied.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>leak</code>               (<code>float or None</code>)           \u2013            <p>The negative slope applied to negative inputs.</p> </li> <li> <code>sub</code>               (<code>float or None</code>)           \u2013            <p>The value subtracted from the activation output.</p> </li> <li> <code>maxv</code>               (<code>float or None</code>)           \u2013            <p>The upper bound for output clipping.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Applies the configured activation transformation to the input tensor.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; act = GeneralReLU(leak=0.1, sub=0.4, maxv=6.0)\n&gt;&gt;&gt; x = torch.tensor([-2.0, -0.5, 0.5, 2.0])\n&gt;&gt;&gt; act(x)\ntensor([-0.6000, -0.4500,  0.1000,  1.6000])\n</code></pre>"},{"location":"activations/#cmn_ai.activations.GeneralRelu.forward","title":"<code>forward(x)</code>","text":"<p>Apply the generalized ReLU activation.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Activated tensor, possibly leaky for negative values, with optional subtraction and clipping applied.</p> </li> </ul>"},{"location":"learner/","title":"Learner","text":"<p>Learner module for training PyTorch models with callback system.</p> <p>This module provides a <code>Learner</code> class that handles the training loop of PyTorch models using a customizable callback system. The training loop consists of a minimal set of instructions that can be extended and customized through callbacks.</p> <p>The basic training loop iterates through data and:</p> <ul> <li>Computes the output of the model from the input</li> <li>Calculates a loss between this output and the desired target</li> <li>Computes the gradients of this loss with respect to model parameters</li> <li>Updates the parameters accordingly</li> <li>Zeros all the gradients</li> </ul> <p>Any customization of this training loop is defined in a <code>Callback</code> object. A callback can implement actions on the following events:</p> <ul> <li><code>before_fit</code>: Called before doing anything, ideal for initial setup</li> <li><code>before_epoch</code>: Called at the beginning of each epoch, useful for any   behavior you need to reset at each epoch</li> <li><code>before_train</code>: Called at the beginning of the training part of an epoch</li> <li><code>before_batch</code>: Called at the beginning of each batch, just after drawing   said batch. It can be used to do any setup necessary for the batch   (like hyper-parameter scheduling) or to change the input/target before   it goes in the model (change of the input with techniques like mixup)</li> <li><code>after_pred</code>: Called after computing the output of the model on the batch.   It can be used to change that output before it's fed to the loss function</li> <li><code>after_loss</code>: Called after the loss has been computed, but before the   backward pass. It can be used to add any penalty to the loss   (AR or TAR in RNN training for instance)</li> <li><code>after_cancel_backward</code>: Reached immediately after <code>CancelBackwardException</code></li> <li><code>after_backward</code>: Called after the backward pass, but before updating   the parameters. It can be used to do any change to the gradients   before any updates (gradient clipping for instance)</li> <li><code>after_cancel_step</code>: Reached immediately after <code>CancelStepException</code></li> <li><code>after_step</code>: Called after the step and before gradients are zeroed</li> <li><code>after_cancel_batch</code>: Reached immediately after <code>CancelBatchException</code>   before proceeding to <code>after_batch</code></li> <li><code>after_batch</code>: Called at the end of a batch, for any clean-up before the next one</li> <li><code>after_cancel_train</code>: Reached immediately after <code>CancelTrainException</code>   before proceeding to <code>after_train</code></li> <li><code>after_train</code>: Called at the end of the training phase of an epoch</li> <li><code>before_validate</code>: Called at the beginning of the validation phase of an epoch,   useful for any setup needed specifically for validation</li> <li><code>after_cancel_validate</code>: Reached immediately after <code>CancelValidateException</code>   before proceeding to <code>after_validate</code></li> <li><code>after_validate</code>: Called at the end of the validation phase of an epoch</li> <li><code>after_cancel_epoch</code>: Reached immediately after <code>CancelEpochException</code>   before proceeding to <code>after_epoch</code></li> <li><code>after_epoch</code>: Called at the end of an epoch, for any clean-up before the next one</li> <li><code>after_cancel_fit</code>: Reached immediately after <code>CancelFitException</code>   before proceeding to <code>after_fit</code></li> <li><code>after_fit</code>: Called at the end of training, for any final clean-up</li> </ul> <p>Classes:</p> <ul> <li> <code>Learner</code>           \u2013            <p>Main class for training PyTorch models with callback system.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>params_getter</code>             \u2013              <p>Get all parameters of a model recursively.</p> </li> </ul> <p>Examples:</p> <p>Basic usage:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.learner import Learner\n&gt;&gt;&gt; from cmn_ai.utils.data import DataLoaders\n&gt;&gt;&gt; import torch.nn as nn\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a simple model and data loaders\n&gt;&gt;&gt; model = nn.Linear(10, 1)\n&gt;&gt;&gt; dls = DataLoaders(train_dl, valid_dl)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create learner\n&gt;&gt;&gt; learner = Learner(model, dls, loss_func=nn.MSELoss())\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Train the model\n&gt;&gt;&gt; learner.fit(n_epochs=10)\n</code></pre> <p>Learning rate finding:</p> <pre><code>&gt;&gt;&gt; learner.lr_find(start_lr=1e-6, num_iter=200)\n</code></pre> <p>Model checkpointing:</p> <pre><code>&gt;&gt;&gt; learner.save_model(\"checkpoint.pt\", with_opt=True, with_epoch=True)\n&gt;&gt;&gt; learner.load_model(\"checkpoint.pt\", with_opt=True)\n</code></pre> Notes <p>The <code>TrainEvalCallback</code> is automatically added to all learners and doesn't need to be provided manually. This callback handles the basic training and validation loop management.</p> See Also <p>cmn_ai.callbacks.core.Callback : Base callback class cmn_ai.callbacks.training.TrainEvalCallback : Default training callback cmn_ai.utils.data.DataLoaders : Data loader container</p>"},{"location":"learner/#cmn_ai.learner.Learner","title":"<code>Learner</code>","text":"<p>A learner class that handles training loop of PyTorch models.</p> <p>This class provides a customizable training loop using a callback system. It handles model training, validation, saving/loading, and learning rate finding. The training process can be customized through various callback events.</p> <p>Attributes:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The PyTorch model to train.</p> </li> <li> <code>dls</code>               (<code>DataLoaders</code>)           \u2013            <p>Training and validation data loaders.</p> </li> <li> <code>n_inp</code>               (<code>int</code>)           \u2013            <p>Number of inputs to the model.</p> </li> <li> <code>loss_func</code>               (<code>Callable[[tensor, tensor], tensor]</code>)           \u2013            <p>Loss function that takes predictions and targets.</p> </li> <li> <code>opt_func</code>               (<code>Optimizer</code>)           \u2013            <p>Optimizer class (not instance).</p> </li> <li> <code>lr</code>               (<code>float</code>)           \u2013            <p>Learning rate for training.</p> </li> <li> <code>splitter</code>               (<code>Callable[[Module], Iterable[Parameter]]</code>)           \u2013            <p>Function to split model's parameters into groups.</p> </li> <li> <code>path</code>               (<code>Path</code>)           \u2013            <p>Base path for saving artifacts.</p> </li> <li> <code>model_dir_path</code>               (<code>Path</code>)           \u2013            <p>Directory path for saving models.</p> </li> <li> <code>callbacks</code>               (<code>list[Callback]</code>)           \u2013            <p>List of all callbacks used by the learner.</p> </li> <li> <code>logger</code>               (<code>Any</code>)           \u2013            <p>Logger for metrics. Default is <code>print</code> but typically modified by callbacks such as <code>ProgressCallback</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.learner import Learner\n&gt;&gt;&gt; from cmn_ai.utils.data import DataLoaders\n&gt;&gt;&gt; import torch.nn as nn\n&gt;&gt;&gt;\n&gt;&gt;&gt; model = nn.Linear(10, 1)\n&gt;&gt;&gt; dls = DataLoaders(train_dl, valid_dl)\n&gt;&gt;&gt; learner = Learner(model, dls, loss_func=nn.MSELoss())\n&gt;&gt;&gt; learner.fit(n_epochs=5)\n</code></pre>"},{"location":"learner/#cmn_ai.learner.Learner.training","title":"<code>training</code>  <code>property</code> <code>writable</code>","text":"<p>Get the training mode of the model.</p> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>True if the model is in training mode, False otherwise.</p> </li> </ul>"},{"location":"learner/#cmn_ai.learner.Learner.__init__","title":"<code>__init__(model, dls, n_inp=1, loss_func=F.mse_loss, opt_func=opt.SGD, lr=0.01, splitter=params_getter, path='.', model_dir='models', callbacks=None)</code>","text":"<p>Initialize the Learner.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The PyTorch model to train.</p> </li> <li> <code>dls</code>               (<code>DataLoaders</code>)           \u2013            <p>Training and validation data loaders.</p> </li> <li> <code>n_inp</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of inputs to the model.</p> </li> <li> <code>loss_func</code>               (<code>Callable[[tensor, tensor], tensor]</code>, default:                   <code>F.mse_loss</code> )           \u2013            <p>Loss function that takes predictions and targets.</p> </li> <li> <code>opt_func</code>               (<code>Optimizer</code>, default:                   <code>opt.SGD</code> )           \u2013            <p>Optimizer class (not instance).</p> </li> <li> <code>lr</code>               (<code>float</code>, default:                   <code>1e-2</code> )           \u2013            <p>Learning rate for training.</p> </li> <li> <code>splitter</code>               (<code>Callable[[Module], Iterable[Parameter]]</code>, default:                   <code>params_getter</code> )           \u2013            <p>Function to split model's parameters into groups.</p> </li> <li> <code>path</code>               (<code>str | Path</code>, default:                   <code>\".\"</code> )           \u2013            <p>Base path for saving artifacts.</p> </li> <li> <code>model_dir</code>               (<code>str</code>, default:                   <code>\"models\"</code> )           \u2013            <p>Model directory name relative to <code>path</code>.</p> </li> <li> <code>callbacks</code>               (<code>Iterable[Callback] | None</code>, default:                   <code>None</code> )           \u2013            <p>Initial callbacks to add to the learner.</p> </li> </ul> Notes <p>The <code>TrainEvalCallback</code> is automatically added to the callbacks list and doesn't need to be provided manually.</p>"},{"location":"learner/#cmn_ai.learner.Learner.fit","title":"<code>fit(n_epochs=1, run_train=True, run_valid=True, callbacks=None, lr=None, reset_opt=False)</code>","text":"<p>Fit the model for a specified number of epochs.</p> <p>Parameters:</p> <ul> <li> <code>n_epochs</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of epochs to train the model.</p> </li> <li> <code>run_train</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to run training passes.</p> </li> <li> <code>run_valid</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to run validation passes.</p> </li> <li> <code>callbacks</code>               (<code>Iterable[Callback] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional callbacks to add temporarily for this fit call. These callbacks will be removed after training completes.</p> </li> <li> <code>lr</code>               (<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Learning rate to use. If None, uses the learner's default lr.</p> </li> <li> <code>reset_opt</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to reset the optimizer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; learner.fit(n_epochs=10, lr=0.001)\n&gt;&gt;&gt; learner.fit(n_epochs=5, run_valid=False)\n</code></pre>"},{"location":"learner/#cmn_ai.learner.Learner.load_model","title":"<code>load_model(path=None, with_opt=False, with_epoch=False, with_loss=False)</code>","text":"<p>Load the model and optionally optimizer state, epoch, and loss.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str | Path | None</code>, default:                   <code>None</code> )           \u2013            <p>Model's file path. If None, uses <code>learner.model_dir_path</code>/model.</p> </li> <li> <code>with_opt</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to load the optimizer state.</p> </li> <li> <code>with_epoch</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to load the current epoch number.</p> </li> <li> <code>with_loss</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to load the current loss value.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; learner.load_model(\"checkpoint.pt\", with_opt=True)\n&gt;&gt;&gt; learner.load_model()  # Uses default path\n</code></pre>"},{"location":"learner/#cmn_ai.learner.Learner.lr_find","title":"<code>lr_find(start_lr=1e-07, gamma=1.3, num_iter=100, stop_div=True, max_mult=4)</code>","text":"<p>Find optimal learning rate using exponential schedule.</p> <p>This method implements the learning rate finder described in Cyclical Learning Rates for Training Neural Networks. It tries different learning rates using an exponential schedule and plots learning rate vs loss to help identify the optimal learning rate.</p> <p>Parameters:</p> <ul> <li> <code>start_lr</code>               (<code>float</code>, default:                   <code>1e-7</code> )           \u2013            <p>Starting learning rate for the search.</p> </li> <li> <code>gamma</code>               (<code>float</code>, default:                   <code>1.3</code> )           \u2013            <p>Multiplicative factor for learning rate increase.</p> </li> <li> <code>num_iter</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Number of iterations to run the learning rate search.</p> </li> <li> <code>stop_div</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to stop training if the loss diverges.</p> </li> <li> <code>max_mult</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>Divergence threshold. If loss &gt;= max_mult * minimum loss, training stops.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; learner.lr_find(start_lr=1e-6, num_iter=200)\n</code></pre>"},{"location":"learner/#cmn_ai.learner.Learner.save_model","title":"<code>save_model(path=None, with_opt=False, with_epoch=False, with_loss=False, pickle_protocol=pickle.HIGHEST_PROTOCOL)</code>","text":"<p>Save the model and optionally optimizer state, epoch, and loss.</p> <p>This method is useful for checkpointing during training. It saves the model state dict and optionally includes optimizer state, current epoch, and current loss.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str | Path | None</code>, default:                   <code>None</code> )           \u2013            <p>File path to save the model. If None, uses <code>learner.model_dir_path</code>/model.</p> </li> <li> <code>with_opt</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to save the optimizer state.</p> </li> <li> <code>with_epoch</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to save the current epoch number.</p> </li> <li> <code>with_loss</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to save the current loss value.</p> </li> <li> <code>pickle_protocol</code>               (<code>int</code>, default:                   <code>pickle.HIGHEST_PROTOCOL</code> )           \u2013            <p>Protocol used by pickler when saving the checkpoint.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; learner.save_model(\"checkpoint.pt\", with_opt=True, with_epoch=True)\n&gt;&gt;&gt; learner.save_model()  # Uses default path\n</code></pre>"},{"location":"learner/#cmn_ai.learner.Learner.show_batch","title":"<code>show_batch(sample_sz=1, callbacks=None, **kwargs)</code>","text":"<p>Show a sample batch of input data.</p> <p>This method displays what the model would see when making predictions, including all transformations and augmentations applied to the input.</p> <p>Parameters:</p> <ul> <li> <code>sample_sz</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of input samples to show.</p> </li> <li> <code>callbacks</code>               (<code>Iterable[Callback] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional callbacks to add temporarily for this operation. These callbacks will be removed after the operation completes.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional arguments passed to the show_batch implementation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NotImplementedError</code>             \u2013            <p>Different types of <code>Learner</code>'s must implement their own version depending on the type of input data. For example, <code>VisionLearner</code>'s would show images.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; learner.show_batch(sample_sz=3)\n</code></pre>"},{"location":"learner/#cmn_ai.learner.Learner.summary","title":"<code>summary(verbose=2, **kwargs)</code>","text":"<p>Generate and display model summary using torchinfo.</p> <p>Parameters:</p> <ul> <li> <code>verbose</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>Verbosity level for the summary output.</p> </li> <li> <code>**kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional arguments passed to torchinfo.summary.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>           \u2013            <p>The summary object returned by torchinfo.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; learner.summary(verbose=1)\n&gt;&gt;&gt; learner.summary(col_names=[\"input_size\", \"output_size\"])\n</code></pre>"},{"location":"learner/#cmn_ai.learner.params_getter","title":"<code>params_getter(model)</code>","text":"<p>Get all parameters of a model recursively.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>The PyTorch model to extract parameters from.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>Parameter</code>           \u2013            <p>Each parameter of the model.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; model = nn.Linear(10, 1)\n&gt;&gt;&gt; params = list(params_getter(model))\n&gt;&gt;&gt; len(params)\n2\n</code></pre>"},{"location":"losses/","title":"Losses","text":"<p>Loss functions and utilities for neural network training.</p> <p>This module provides various loss functions and utilities for training neural networks. It includes specialized loss functions like label smoothing cross-entropy and utilities for loss reduction and non-reduction contexts.</p> <p>Functions:</p> <ul> <li> <code>reduce_loss : Callable</code>             \u2013              <p>Reduce loss tensor using specified reduction method.</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>NoneReduce : object</code>           \u2013            <p>Context manager to force non-reduction on loss functions.</p> </li> <li> <code>LabelSmoothingCrossEntropy : nn.Module</code>           \u2013            <p>Cross-entropy loss with label smoothing for regularization.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Use label smoothing cross-entropy\n&gt;&gt;&gt; loss_func = LabelSmoothingCrossEntropy(eps=0.1)\n&gt;&gt;&gt; loss = loss_func(outputs, targets)\n</code></pre> <pre><code>&gt;&gt;&gt; # Temporarily disable loss reduction\n&gt;&gt;&gt; with NoneReduce(nn.CrossEntropyLoss()) as loss_func:\n...     loss = loss_func(outputs, targets)  # No reduction applied\n</code></pre> <pre><code>&gt;&gt;&gt; # Reduce loss manually\n&gt;&gt;&gt; reduced_loss = reduce_loss(loss, reduction=\"mean\")\n</code></pre>"},{"location":"losses/#cmn_ai.losses.LabelSmoothingCrossEntropy","title":"<code>LabelSmoothingCrossEntropy</code>","text":"<p>               Bases: <code>Module</code></p> <p>Cross-entropy loss with label smoothing for regularization.</p> <p>Label smoothing is a regularization technique that prevents the model from becoming overconfident in its predictions. Instead of using hard targets (1 for correct class, 0 for others), it uses soft targets where the correct class gets probability <code>1 - \u03b5</code> and all other classes get <code>\u03b5 / (num_classes - 1)</code>.</p> <p>This helps improve generalization and makes the model more robust to label noise and overfitting.</p> <p>Attributes:</p> <ul> <li> <code>eps</code>               (<code>float</code>)           \u2013            <p>The smoothing factor (epsilon) that controls the amount of smoothing.</p> </li> <li> <code>reduction</code>               (<code>str</code>)           \u2013            <p>The reduction method applied to the loss tensor.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create label smoothing cross-entropy loss\n&gt;&gt;&gt; loss_func = LabelSmoothingCrossEntropy(eps=0.1)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use in training\n&gt;&gt;&gt; outputs = model(inputs)  # Shape: (batch_size, num_classes)\n&gt;&gt;&gt; targets = torch.tensor([0, 1, 2])  # Shape: (batch_size,)\n&gt;&gt;&gt; loss = loss_func(outputs, targets)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With custom reduction\n&gt;&gt;&gt; loss_func = LabelSmoothingCrossEntropy(eps=0.05, reduction=\"sum\")\n</code></pre>"},{"location":"losses/#cmn_ai.losses.LabelSmoothingCrossEntropy.__init__","title":"<code>__init__(eps=0.1, reduction='mean')</code>","text":"<p>Initialize the label smoothing cross-entropy loss.</p> <p>Parameters:</p> <ul> <li> <code>eps</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>The smoothing factor. Should be between 0 and 1. - 0: No smoothing (standard cross-entropy) - 1: Maximum smoothing (uniform distribution)</p> </li> <li> <code>reduction</code>               (<code>str</code>, default:                   <code>\"mean\"</code> )           \u2013            <p>The reduction method to apply to the loss tensor. Options: \"mean\", \"sum\", or \"none\".</p> </li> </ul> Notes <p>The smoothing factor <code>eps</code> controls how much the target distribution is smoothed. A value of 0.1 means the correct class gets probability 0.9 and the remaining 0.1 is distributed equally among other classes.</p>"},{"location":"losses/#cmn_ai.losses.LabelSmoothingCrossEntropy.forward","title":"<code>forward(output, target)</code>","text":"<p>Compute the label smoothing cross-entropy loss.</p> <p>Parameters:</p> <ul> <li> <code>output</code>               (<code>Tensor</code>)           \u2013            <p>The model's output logits. Shape: (batch_size, num_classes)</p> </li> <li> <code>target</code>               (<code>Tensor</code>)           \u2013            <p>The target class indices. Shape: (batch_size,)</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>The computed loss value.</p> </li> </ul> Notes <p>The loss is computed as: <pre><code>loss = (1 - eps) * NLL_loss + eps * KL_divergence\n</code></pre> where NLL_loss is the negative log-likelihood loss and KL_divergence is the KL divergence between the predicted distribution and a uniform distribution over all classes.</p>"},{"location":"losses/#cmn_ai.losses.NoneReduce","title":"<code>NoneReduce</code>","text":"<p>Context manager to force non-reduction on loss functions.</p> <p>This class provides a context manager that temporarily modifies a loss function to return unreduced loss tensors. This is useful when you need to access individual loss values, such as in mixup training or when implementing custom loss reduction strategies.</p> <p>Attributes:</p> <ul> <li> <code>loss_func</code>               (<code>Callable</code>)           \u2013            <p>The loss function to be modified.</p> </li> <li> <code>old_reduction</code>               (<code>str | None</code>)           \u2013            <p>The original reduction setting of the loss function.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Temporarily disable reduction for cross-entropy loss\n&gt;&gt;&gt; with NoneReduce(nn.CrossEntropyLoss()) as loss_func:\n...     loss = loss_func(outputs, targets)  # Shape: (batch_size,)\n...     # Process individual loss values\n...     weighted_loss = loss * weights\n</code></pre> <pre><code>&gt;&gt;&gt; # Use with custom loss functions\n&gt;&gt;&gt; with NoneReduce(my_custom_loss) as loss_func:\n...     unreduced_loss = loss_func(predictions, targets)\n</code></pre>"},{"location":"losses/#cmn_ai.losses.NoneReduce.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context and modify the loss function.</p> <p>Returns:</p> <ul> <li> <code>Callable</code>           \u2013            <p>The modified loss function that returns unreduced tensors.</p> </li> </ul> Notes <p>If the loss function has a <code>reduction</code> attribute, it will be temporarily set to \"none\". Otherwise, a partial function is returned with <code>reduction=\"none\"</code> as a keyword argument.</p>"},{"location":"losses/#cmn_ai.losses.NoneReduce.__exit__","title":"<code>__exit__(exc_type, exc_val, traceback)</code>","text":"<p>Exit the context and restore the original loss function.</p> <p>Parameters:</p> <ul> <li> <code>exc_type</code>               (<code>type | None</code>)           \u2013            <p>Exception type if an exception occurred.</p> </li> <li> <code>exc_val</code>               (<code>Exception | None</code>)           \u2013            <p>Exception value if an exception occurred.</p> </li> <li> <code>traceback</code>               (<code>traceback | None</code>)           \u2013            <p>Traceback if an exception occurred.</p> </li> </ul> Notes <p>This method restores the original reduction setting of the loss function if it was modified. If no modification was made (e.g., the loss function didn't have a <code>reduction</code> attribute), nothing is done.</p>"},{"location":"losses/#cmn_ai.losses.NoneReduce.__init__","title":"<code>__init__(loss_func)</code>","text":"<p>Initialize the context manager.</p> <p>Parameters:</p> <ul> <li> <code>loss_func</code>               (<code>Callable</code>)           \u2013            <p>The loss function to be modified. Should either have a <code>reduction</code> attribute (like PyTorch loss functions) or accept a <code>reduction</code> parameter.</p> </li> </ul>"},{"location":"losses/#cmn_ai.losses.reduce_loss","title":"<code>reduce_loss(loss, reduction=None)</code>","text":"<p>Reduce loss tensor using specified reduction method.</p> <p>This function applies the specified reduction method to a loss tensor. It supports the standard PyTorch reduction methods: \"mean\", \"sum\", or None (no reduction).</p> <p>Parameters:</p> <ul> <li> <code>loss</code>               (<code>Tensor</code>)           \u2013            <p>The loss tensor to be reduced.</p> </li> <li> <code>reduction</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The reduction method to apply: - \"mean\": Compute the mean of all elements - \"sum\": Compute the sum of all elements - None: Return the tensor as-is (no reduction)</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>The reduced loss tensor. If reduction is None, returns the original tensor.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Reduce to mean\n&gt;&gt;&gt; loss = torch.tensor([1.0, 2.0, 3.0])\n&gt;&gt;&gt; mean_loss = reduce_loss(loss, reduction=\"mean\")  # 2.0\n</code></pre> <pre><code>&gt;&gt;&gt; # Reduce to sum\n&gt;&gt;&gt; sum_loss = reduce_loss(loss, reduction=\"sum\")  # 6.0\n</code></pre> <pre><code>&gt;&gt;&gt; # No reduction\n&gt;&gt;&gt; unreduced = reduce_loss(loss, reduction=None)  # tensor([1.0, 2.0, 3.0])\n</code></pre>"},{"location":"plot/","title":"Plotting","text":"<p>This module provides different plotting utilities that are commonly used in ML context such as plotting a grid of images or show a single image.</p>"},{"location":"plot/#cmn_ai.plot.get_grid","title":"<code>get_grid(n, nrows=None, ncols=None, title=None, weight='bold', size=14, **kwargs)</code>","text":"<p>Return a grid of <code>n</code> axes, <code>rows</code> by <code>cols</code>. <code>nrows</code> and <code>ncols</code> are mutually exclusive. This means you only need to pass one of them and the other will be inferred.</p> <p>Parameters:</p> <ul> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>Number of axes.</p> </li> <li> <code>nrows</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of rows, default=<code>int(math.sqrt(n))</code>.</p> </li> <li> <code>ncols</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of columns, default=<code>ceil(n/rows)</code>.</p> </li> <li> <code>title</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Title of the Figure.</p> </li> <li> <code>weight</code>               (<code>str</code>, default:                   <code>'bold'</code> )           \u2013            <p>Title font weight.</p> </li> <li> <code>size</code>               (<code>int</code>, default:                   <code>14</code> )           \u2013            <p>Title font size.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>fig</code> (              <code>Figure</code> )          \u2013            <p>Top level container for all axes.</p> </li> <li> <code>ax</code> (              <code>array of Axes</code> )          \u2013            <p>Array of axes.</p> </li> </ul>"},{"location":"plot/#cmn_ai.plot.show_image","title":"<code>show_image(image, ax=None, figsize=None, title=None, noframe=True, **kwargs)</code>","text":"<p>Show a PIL or PyTorch image on <code>ax</code>.</p> <p>Parameters:</p> <ul> <li> <code>image</code>               (<code>PIL image or array-like</code>)           \u2013            <p>Image data.</p> </li> <li> <code>ax</code>               (<code>Axes</code>, default:                   <code>None</code> )           \u2013            <p>Axes to plot the image on.</p> </li> <li> <code>figsize</code>               (<code>tuple</code>, default:                   <code>None</code> )           \u2013            <p>Width, height in inches of the returned Figure</p> </li> <li> <code>title</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Title of the image</p> </li> <li> <code>noframe</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to remove axis from the plotted image.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ax</code> (              <code>AxesImage</code> )          \u2013            <p>Plotted image on <code>ax</code>.</p> </li> </ul>"},{"location":"plot/#cmn_ai.plot.show_images","title":"<code>show_images(images, nrows=None, ncols=None, titles=None, **kwargs)</code>","text":"<p>Show all images as subplots with <code>nrows</code> x <code>ncols</code> using <code>titles</code>.</p> <p>Parameters:</p> <ul> <li> <code>images</code>               (<code>list or array - like</code>)           \u2013            <p>List of images to show.</p> </li> <li> <code>nrows</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of rows in the grid.</p> </li> <li> <code>ncols</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of columns in the grid.</p> </li> <li> <code>titles</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of titles for each image.</p> </li> </ul>"},{"location":"plot/#cmn_ai.plot.subplots","title":"<code>subplots(nrows=1, ncols=1, figsize=None, imsize=3, suptitle=None, **kwargs)</code>","text":"<p>A figure and set of subplots to display images of <code>imsize</code> inches.</p> <p>Parameters:</p> <ul> <li> <code>nrows</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of rows in returned axes grid.</p> </li> <li> <code>ncols</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of columns in returned axes grid.</p> </li> <li> <code>figsize</code>               (<code>tuple</code>, default:                   <code>None</code> )           \u2013            <p>Width, height in inches of the returned Figure.</p> </li> <li> <code>imsize</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Size (in inches) of images that will be displayed in the returned figure.</p> </li> <li> <code>suptitle</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Title of the Figure.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>fig</code> (              <code>Figure</code> )          \u2013            <p>Top level container for all axes.</p> </li> <li> <code>ax</code> (              <code>array of Axes</code> )          \u2013            <p>Array of axes.</p> </li> </ul>"},{"location":"callbacks/core/","title":"Core","text":"<p>Core callback system for training loop management.</p> <p>This module provides the foundational callback system that allows for custom behavior injection into machine learning training loops. It defines the base <code>Callback</code> class and a set of control flow exceptions that enable fine-grained control over the training process.</p> <p>Classes:</p> <ul> <li> <code>Callback</code>           \u2013            <p>Base class for all callbacks, providing the interface for training loop integration and utility methods for callback management.</p> </li> <li> <code>CancelFitException</code>           \u2013            <p>Exception to stop training and move to after_fit phase.</p> </li> <li> <code>CancelEpochException</code>           \u2013            <p>Exception to stop current epoch and move to after_epoch phase.</p> </li> <li> <code>CancelTrainException</code>           \u2013            <p>Exception to stop training phase and move to after_train phase.</p> </li> <li> <code>CancelValidateException</code>           \u2013            <p>Exception to stop validation phase and move to after_validate phase.</p> </li> <li> <code>CancelBatchException</code>           \u2013            <p>Exception to stop current batch and move to after_batch phase.</p> </li> <li> <code>CancelStepException</code>           \u2013            <p>Exception to skip optimizer step and move to after_step phase.</p> </li> <li> <code>CancelBackwardException</code>           \u2013            <p>Exception to skip backward pass and move to after_backward phase.</p> </li> </ul> Notes <p>The callback system works by defining specific event names that correspond to different phases of the training loop. Callbacks can implement methods with these event names to be called at the appropriate times:</p> <ul> <li><code>before_fit</code>: Called before training begins</li> <li><code>after_fit</code>: Called after training completes</li> <li><code>before_epoch</code>: Called before each epoch</li> <li><code>after_epoch</code>: Called after each epoch</li> <li><code>before_train</code>: Called before training phase of each epoch</li> <li><code>after_train</code>: Called after training phase of each epoch</li> <li><code>before_validate</code>: Called before validation phase of each epoch</li> <li><code>after_validate</code>: Called after validation phase of each epoch</li> <li><code>before_batch</code>: Called before processing each batch</li> <li><code>after_batch</code>: Called after processing each batch</li> <li><code>before_step</code>: Called before optimizer step</li> <li><code>after_step</code>: Called after optimizer step</li> <li><code>before_backward</code>: Called before backward pass</li> <li><code>after_backward</code>: Called after backward pass</li> </ul> <p>Examples:</p> <p>Creating a custom callback:</p> <pre><code>&gt;&gt;&gt; class MyCallback(Callback):\n...     def before_epoch(self):\n...         print(f\"Starting epoch {self.epoch}\")\n...\n...     def after_batch(self):\n...         if self.loss &gt; 0.5:\n...             raise CancelEpochException(\"Loss too high\")\n</code></pre> <p>Using control flow exceptions:</p> <pre><code>&gt;&gt;&gt; class EarlyStoppingCallback(Callback):\n...     def after_epoch(self):\n...         if self.epoch &gt; 10 and self.valid_loss &gt; self.best_loss:\n...             raise CancelFitException(\"Early stopping triggered\")\n</code></pre>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback","title":"<code>Callback</code>","text":"<p>Base class for all callbacks.</p> <p>A callback is a mechanism to inject custom behavior into the training loop at specific points. Callbacks can be used for logging, early stopping, learning rate scheduling, and other custom functionality.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>The order in which callbacks should be executed. Lower numbers are executed first. Default is 0.</p> </li> <li> <code>learner</code>               (<code>Any</code>)           \u2013            <p>Reference to the learner object, set by <code>set_learner()</code>.</p> </li> </ul> Notes <p>Subclasses should implement specific callback methods that correspond to training events (e.g., <code>before_fit</code>, <code>after_epoch</code>, etc.).</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns the name of the callback after removing the word <code>callback</code> and then convert it to snake (split words by underscores).</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The callback name in snake_case format with 'Callback' suffix removed. For example, 'TestCallback' becomes 'test'.</p> </li> </ul>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.__call__","title":"<code>__call__(event_nm)</code>","text":"<p>Call the callback method corresponding to the given event name.</p> <p>If the callback has a method with the same name as the event, it will be called. Otherwise, nothing happens.</p> <p>Parameters:</p> <ul> <li> <code>event_nm</code>               (<code>str</code>)           \u2013            <p>The name of the event to handle (e.g., 'before_fit', 'after_epoch').</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>           \u2013            <p>The return value of the callback method, or None if the method doesn't exist.</p> </li> </ul>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.__getattr__","title":"<code>__getattr__(k)</code>","text":"<p>Allow access to learner attributes directly through the callback.</p> <p>This would allow us to use <code>self.obj</code> instead of <code>self.learner.obj</code> when we know <code>obj</code> is in learner because it will only be called when <code>getattribute</code> returns <code>AttributeError</code>.</p> <p>Parameters:</p> <ul> <li> <code>k</code>               (<code>str</code>)           \u2013            <p>The attribute name to access from the learner.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>           \u2013            <p>The attribute value from the learner object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AttributeError</code>             \u2013            <p>If the attribute is not found in the learner object.</p> </li> </ul>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the callback.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.camel2snake","title":"<code>camel2snake(name)</code>  <code>staticmethod</code>","text":"<p>Convert camelCase name to snake_case by inserting underscores.</p> <p>Inserts underscores between lowercase and uppercase letters. For example, <code>TestCallback</code> becomes <code>test_callback</code>.</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The camelCase string to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The converted snake_case string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Callback.camel2snake(\"TestCallback\")\n'test_callback'\n&gt;&gt;&gt; Callback.camel2snake(\"MyCustomCallback\")\n'my_custom_callback'\n</code></pre>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.set_learner","title":"<code>set_learner(learner)</code>","text":"<p>Set the learner as an attribute so that callbacks can access learner's attributes without the need to pass <code>learner</code> for every single method in every callback.</p> <p>Parameters:</p> <ul> <li> <code>learner</code>               (<code>Any</code>)           \u2013            <p>Learner that the callback will be called when some events happens. This object will be stored as <code>self.learner</code>.</p> </li> </ul>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelBackwardException","title":"<code>CancelBackwardException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised to skip the backward pass and move to <code>after_backward</code>.</p> <p>This exception is used to skip the backward pass computation and immediately proceed to the after_backward phase.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelBatchException","title":"<code>CancelBatchException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised to stop current batch and move to <code>after_batch</code>.</p> <p>This exception is used to interrupt the current batch processing and immediately proceed to the after_batch phase.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelEpochException","title":"<code>CancelEpochException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised to stop current epoch and move to <code>after_epoch</code>.</p> <p>This exception is used to interrupt the current epoch and immediately proceed to the after_epoch phase.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelFitException","title":"<code>CancelFitException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised to stop training and move to <code>after_fit</code>.</p> <p>This exception is used to interrupt the training process and immediately proceed to the after_fit phase of the training loop.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelStepException","title":"<code>CancelStepException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised to skip stepping the optimizer and move to <code>after_step</code>.</p> <p>This exception is used to skip the optimizer step and immediately proceed to the after_step phase.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelTrainException","title":"<code>CancelTrainException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised to stop training current epoch and move to <code>after_train</code>.</p> <p>This exception is used to interrupt the training phase of the current epoch and immediately proceed to the after_train phase.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelValidateException","title":"<code>CancelValidateException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised to stop validation phase and move to <code>after_validate</code>.</p> <p>This exception is used to interrupt the validation phase and immediately proceed to the after_validate phase.</p>"},{"location":"callbacks/hook/","title":"Hooks","text":"<p>Hooks for inspecting neural network activations and gradients during training.</p> <p>This module provides utilities for registering hooks on PyTorch modules to inspect what is happening during forward and backward passes. This is useful for computing statistics of activations and gradients, debugging training issues, and monitoring model behavior.</p> <p>Hooks are very useful to inspect what is happening during the forward and backward passes such as computing stats of the activations and gradients.</p> <p>Functions:</p> <ul> <li> <code>compute_stats : Callable</code>             \u2013              <p>Compute means, std, and histogram of module activations/gradients.</p> </li> <li> <code>get_hist : Callable</code>             \u2013              <p>Return matrix-ready for plotting heatmap of activations/gradients.</p> </li> <li> <code>get_min : Callable</code>             \u2013              <p>Compute percentage of activations/gradients around zero from histogram.</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>Hook : object</code>           \u2013            <p>Register either a forward or a backward hook on a single module.</p> </li> <li> <code>Hooks : object</code>           \u2013            <p>Register hooks on multiple modules with context manager support.</p> </li> <li> <code>HooksCallback : Callback</code>           \u2013            <p>Base class to run hooks on modules as a callback.</p> </li> <li> <code>ActivationStats : HooksCallback</code>           \u2013            <p>Plot means, std, histogram, and dead activations of all modules.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Register a hook on a single module\n&gt;&gt;&gt; hook = Hook(model.layer1, compute_stats)\n&gt;&gt;&gt; # Use as context manager\n&gt;&gt;&gt; with Hook(model.layer1, compute_stats):\n...     output = model(input)\n</code></pre> <pre><code>&gt;&gt;&gt; # Register hooks on multiple modules\n&gt;&gt;&gt; hooks = Hooks(model.children(), compute_stats)\n&gt;&gt;&gt; hooks.remove()  # Clean up\n</code></pre> <pre><code>&gt;&gt;&gt; # Use as callback during training\n&gt;&gt;&gt; stats = ActivationStats(model, is_forward=True)\n&gt;&gt;&gt; learner.add_callback(stats)\n&gt;&gt;&gt; stats.plot_stats()  # Plot activation statistics\n</code></pre>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats","title":"<code>ActivationStats</code>","text":"<p>               Bases: <code>HooksCallback</code></p> <p>Plot activation/gradient statistics for all modules.</p> <p>This class automatically computes and can plot various statistics of module activations (or gradients if <code>is_forward=False</code>), including means, standard deviations, histograms, and dead activation percentages.</p> <p>Attributes:</p> <ul> <li> <code>bins</code>               (<code>int</code>)           \u2013            <p>Number of histogram bins.</p> </li> <li> <code>bins_range</code>               (<code>list | tuple</code>)           \u2013            <p>Range for histogram bins.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Monitor activation statistics during training\n&gt;&gt;&gt; stats = ActivationStats(model, is_forward=True)\n&gt;&gt;&gt; learner.add_callback(stats)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # After training, plot the statistics\n&gt;&gt;&gt; stats.plot_stats()\n&gt;&gt;&gt; stats.plot_hist()\n&gt;&gt;&gt; stats.dead_chart([0, 5])  # Show dead activations in bins 0-4\n</code></pre>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats.__init__","title":"<code>__init__(modules=None, is_forward=True, bins=40, bins_range=(0, 10))</code>","text":"<p>Initialize the activation statistics callback.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Module | Iterable[Module] | None</code>, default:                   <code>None</code> )           \u2013            <p>Modules to register the hook on. If None, uses all model children.</p> </li> <li> <code>is_forward</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to monitor activations (True) or gradients (False).</p> </li> <li> <code>bins</code>               (<code>int</code>, default:                   <code>40</code> )           \u2013            <p>Number of histogram bins.</p> </li> <li> <code>bins_range</code>               (<code>list | tuple</code>, default:                   <code>(0, 10)</code> )           \u2013            <p>Lower and upper bounds for histogram bins.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats.dead_chart","title":"<code>dead_chart(bins_range, figsize=(11, 5))</code>","text":"<p>Plot a line chart of the \"dead\" activations percentage.</p> <p>Shows the percentage of activations/gradients that fall within the specified range around zero over time, which can help identify when neurons become inactive.</p> <p>Parameters:</p> <ul> <li> <code>bins_range</code>               (<code>list | tuple</code>)           \u2013            <p>Range of bins around zero to consider as \"dead\" activations/gradients. Should be a slice-like object (e.g., [0, 5] for bins 0-4).</p> </li> <li> <code>figsize</code>               (<code>tuple</code>, default:                   <code>(11, 5)</code> )           \u2013            <p>Width and height of the figure in inches.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats.plot_hist","title":"<code>plot_hist(figsize=(11, 5))</code>","text":"<p>Plot histogram of activations/gradients as a heatmap.</p> <p>Creates a heatmap visualization where each row represents a histogram bin and each column represents a timestep during training.</p> <p>Parameters:</p> <ul> <li> <code>figsize</code>               (<code>tuple</code>, default:                   <code>(11, 5)</code> )           \u2013            <p>Width and height of the figure in inches.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats.plot_stats","title":"<code>plot_stats(figsize=(10, 4))</code>","text":"<p>Plot means and standard deviations of activations/gradients.</p> <p>Creates two subplots showing the mean and standard deviation of activations/gradients for each layer over time.</p> <p>Parameters:</p> <ul> <li> <code>figsize</code>               (<code>tuple</code>, default:                   <code>(10, 4)</code> )           \u2013            <p>Width and height of the figure in inches.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hook","title":"<code>Hook</code>","text":"<p>Register either a forward or a backward hook on a single module.</p> <p>This class provides a convenient way to register hooks on PyTorch modules and automatically handle cleanup. It can be used as a context manager for automatic hook removal.</p> <p>Attributes:</p> <ul> <li> <code>is_forward</code>               (<code>bool</code>)           \u2013            <p>Whether the hook is a forward or backward hook.</p> </li> <li> <code>hook</code>               (<code>RemovableHandle</code>)           \u2013            <p>The registered hook handle for cleanup.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; hook = Hook(model.layer1, compute_stats)\n&gt;&gt;&gt; # ... use the hook\n&gt;&gt;&gt; hook.remove()\n</code></pre> <pre><code>&gt;&gt;&gt; # Use as context manager\n&gt;&gt;&gt; with Hook(model.layer1, compute_stats):\n...     output = model(input)\n</code></pre>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hook.__del__","title":"<code>__del__()</code>","text":"<p>Destructor to ensure hook removal.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hook.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context manager.</p> <p>Returns:</p> <ul> <li> <code>Hook</code>           \u2013            <p>Self reference for context manager usage.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hook.__exit__","title":"<code>__exit__(*args)</code>","text":"<p>Exit the context manager and remove the hook.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hook.__init__","title":"<code>__init__(module, func, is_forward=True, **kwargs)</code>","text":"<p>Initialize the hook.</p> <p>Parameters:</p> <ul> <li> <code>module</code>               (<code>Module</code>)           \u2013            <p>The module to register the hook on.</p> </li> <li> <code>func</code>               (<code>Callable</code>)           \u2013            <p>The hook function to be registered. Should accept (hook, module, input, output) for forward hooks or (hook, module, grad_input, grad_output) for backward hooks.</p> </li> <li> <code>is_forward</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to register <code>func</code> as a forward or backward hook.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional keyword arguments to pass to the hook function.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hook.remove","title":"<code>remove()</code>","text":"<p>Remove the registered hook.</p> <p>This method removes the hook from the module and should be called to prevent memory leaks.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks","title":"<code>Hooks</code>","text":"<p>Register hooks on multiple modules with convenient management.</p> <p>This class provides a container for multiple hooks with convenient iteration, indexing, and cleanup methods. It can be used as a context manager for automatic cleanup of all hooks.</p> <p>Attributes:</p> <ul> <li> <code>hooks</code>               (<code>list[Hook]</code>)           \u2013            <p>List of registered hooks.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; hooks = Hooks(model.children(), compute_stats)\n&gt;&gt;&gt; for hook in hooks:\n...     print(hook.stats)\n&gt;&gt;&gt; hooks.remove()\n</code></pre> <pre><code>&gt;&gt;&gt; # Use as context manager\n&gt;&gt;&gt; with Hooks(model.children(), compute_stats):\n...     output = model(input)\n</code></pre>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.__del__","title":"<code>__del__()</code>","text":"<p>Destructor to ensure all hooks are removed.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context manager.</p> <p>Returns:</p> <ul> <li> <code>Hooks</code>           \u2013            <p>Self reference for context manager usage.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.__exit__","title":"<code>__exit__(*args)</code>","text":"<p>Exit the context manager and remove all hooks.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Get a hook by index.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>               (<code>int</code>)           \u2013            <p>Index of the hook to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Hook</code>           \u2013            <p>The hook at the specified index.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.__init__","title":"<code>__init__(modules, func, is_forward=True, **kwargs)</code>","text":"<p>Initialize hooks for multiple modules.</p> <p>Parameters:</p> <ul> <li> <code>modules</code>               (<code>Iterable[Module]</code>)           \u2013            <p>Iterable of modules to register hooks on.</p> </li> <li> <code>func</code>               (<code>Callable</code>)           \u2013            <p>The hook function to be registered on each module.</p> </li> <li> <code>is_forward</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to register <code>func</code> as a forward or backward hook.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional keyword arguments to pass to the hook function.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over all hooks.</p> <p>Returns:</p> <ul> <li> <code>Iterator[Hook]</code>           \u2013            <p>Iterator over all registered hooks.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of hooks.</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Number of registered hooks.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.remove","title":"<code>remove()</code>","text":"<p>Remove all registered hooks.</p> <p>This method removes all hooks from their respective modules and should be called to prevent memory leaks.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.HooksCallback","title":"<code>HooksCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Base class to run hooks on modules as a callback.</p> <p>This class provides a convenient way to register and manage hooks during training using the callback system. It automatically handles hook registration before training and cleanup after training.</p> <p>Attributes:</p> <ul> <li> <code>hookfunc</code>               (<code>Callable</code>)           \u2013            <p>The hook function to be registered on modules.</p> </li> <li> <code>on_train</code>               (<code>bool</code>)           \u2013            <p>Whether to run hooks during training.</p> </li> <li> <code>on_valid</code>               (<code>bool</code>)           \u2013            <p>Whether to run hooks during validation.</p> </li> <li> <code>modules</code>               (<code>list[Module]</code>)           \u2013            <p>List of modules to register hooks on.</p> </li> <li> <code>is_forward</code>               (<code>bool</code>)           \u2013            <p>Whether to register forward or backward hooks.</p> </li> <li> <code>hooks</code>               (<code>Hooks</code>)           \u2013            <p>The hooks object managing all registered hooks.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create a custom hook callback\n&gt;&gt;&gt; class MyHookCallback(HooksCallback):\n...     def __init__(self):\n...         super().__init__(compute_stats, on_train=True, on_valid=False)\n&gt;&gt;&gt;\n&gt;&gt;&gt; callback = MyHookCallback()\n&gt;&gt;&gt; learner.add_callback(callback)\n</code></pre>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.HooksCallback.__init__","title":"<code>__init__(hookfunc, on_train=True, on_valid=False, modules=None, is_forward=True)</code>","text":"<p>Initialize the hooks callback.</p> <p>Parameters:</p> <ul> <li> <code>hookfunc</code>               (<code>Callable</code>)           \u2013            <p>The hook function to be registered on modules.</p> </li> <li> <code>on_train</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to run the hook on modules during training.</p> </li> <li> <code>on_valid</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to run the hook on modules during validation.</p> </li> <li> <code>modules</code>               (<code>Module | Iterable[Module] | None</code>, default:                   <code>None</code> )           \u2013            <p>Modules to register the hook on. If None, uses all model children.</p> </li> <li> <code>is_forward</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to register forward or backward hooks.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.HooksCallback.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over all registered hooks.</p> <p>Returns:</p> <ul> <li> <code>Iterator[Hook]</code>           \u2013            <p>Iterator over all registered hooks.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.HooksCallback.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of registered hooks.</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Number of registered hooks.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.HooksCallback.after_fit","title":"<code>after_fit()</code>","text":"<p>Remove all hooks after training ends.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.HooksCallback.before_fit","title":"<code>before_fit()</code>","text":"<p>Register hooks before training begins.</p> <p>If no modules are specified, registers hooks on all model children.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.compute_stats","title":"<code>compute_stats(hook, module, inp, outp, bins=40, bins_range=(0, 10))</code>","text":"<p>Compute the means, std, and histogram of module activations/gradients.</p> <p>This function is designed to be used as a hook function. It computes statistics of the module's output (activations for forward hooks, gradients for backward hooks) and stores them in the hook object.</p> <p>Parameters:</p> <ul> <li> <code>hook</code>               (<code>Hook</code>)           \u2013            <p>The registered hook object where stats will be stored.</p> </li> <li> <code>module</code>               (<code>Module</code>)           \u2013            <p>The module that the hook is registered on.</p> </li> <li> <code>inp</code>               (<code>Tensor</code>)           \u2013            <p>Input to the module (for forward hooks) or gradient input (for backward hooks).</p> </li> <li> <code>outp</code>               (<code>Tensor</code>)           \u2013            <p>Output from the module (for forward hooks) or gradient output (for backward hooks).</p> </li> <li> <code>bins</code>               (<code>int</code>, default:                   <code>40</code> )           \u2013            <p>Number of histogram bins.</p> </li> <li> <code>bins_range</code>               (<code>list | tuple</code>, default:                   <code>(0, 10)</code> )           \u2013            <p>Lower and upper bounds for the histogram bins.</p> </li> </ul> Notes <p>The computed statistics are stored in <code>hook.stats</code> as a tuple of three lists:</p> <ul> <li><code>hook.stats[0]</code>: List of mean values</li> <li><code>hook.stats[1]</code>: List of standard deviation values</li> <li><code>hook.stats[2]</code>: List of histogram tensors</li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.get_hist","title":"<code>get_hist(hook)</code>","text":"<p>Return matrix-ready for plotting heatmap of activations/gradients.</p> <p>Parameters:</p> <ul> <li> <code>hook</code>               (<code>Hook</code>)           \u2013            <p>Hook object containing histogram statistics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Matrix of histogram data ready for plotting as a heatmap. Shape is (bins, timesteps) with log1p applied for better visualization.</p> </li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.get_min","title":"<code>get_min(hook, bins_range)</code>","text":"<p>Compute the percentage of activations/gradients around zero.</p> <p>This function calculates what percentage of the activations or gradients fall within the specified range around zero, which can be useful for identifying \"dead\" neurons or gradients.</p> <p>Parameters:</p> <ul> <li> <code>hook</code>               (<code>Hook</code>)           \u2013            <p>Hook object containing histogram statistics.</p> </li> <li> <code>bins_range</code>               (<code>list | tuple</code>)           \u2013            <p>Range of bins around zero to consider as \"dead\" activations/gradients. Should be a slice-like object (e.g., [0, 5] for bins 0-4).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Percentage of activations/gradients around zero for each timestep. Values range from 0 to 1.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get percentage of activations in bins 0-4 (around zero)\n&gt;&gt;&gt; dead_percentage = get_min(hook, [0, 5])\n&gt;&gt;&gt; print(f\"Dead activations: {dead_percentage.mean():.2%}\")\n</code></pre>"},{"location":"callbacks/schedule/","title":"Schedule","text":"<p>Scheduling callbacks for hyperparameter management during training.</p> <p>This module provides commonly used schedulers for hyperparameters such as learning rate. It is very important to remember to apply hyperparameter updates (such as learning rate) after the optimizer's update. This means that it should be either in <code>before_batch</code> OR <code>after_batch</code> in our framework.</p> <p>We have two choices to schedule hyperparameters:</p> <ol> <li>Use any subclass of <code>Scheduler</code> such as <code>BatchScheduler</code> and pass any scheduler    from PyTorch's schedulers (see https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)</li> <li>Use <code>ParamScheduler</code> and pass it any callable that takes the position and returns    the hyperparameter value such as <code>exp_sched</code></li> </ol> <p>Functions:</p> <ul> <li> <code>annealer : Callable</code>             \u2013              <p>Decorator to create annealer functions.</p> </li> <li> <code>no_sched : Callable</code>             \u2013              <p>Constant scheduler that returns the start value regardless of position.</p> </li> <li> <code>lin_sched : Callable</code>             \u2013              <p>Linear scheduler that interpolates linearly between start and end values.</p> </li> <li> <code>cos_sched : Callable</code>             \u2013              <p>Cosine scheduler that interpolates using cosine annealing.</p> </li> <li> <code>exp_sched : Callable</code>             \u2013              <p>Exponential scheduler that interpolates exponentially between start and end values.</p> </li> <li> <code>cos_1cycle_anneal : Callable</code>             \u2013              <p>Combine two cosine schedulers for 1-cycle learning rate scheduling.</p> </li> <li> <code>combine_scheds : Callable</code>             \u2013              <p>Combine multiple schedulers, each running for a given percentage of training.</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>ParamScheduler : Callback</code>           \u2013            <p>Callback to schedule hyperparameter values during training.</p> </li> <li> <code>Scheduler : Callback</code>           \u2013            <p>Base scheduler to change hyperparameters using PyTorch schedulers.</p> </li> <li> <code>BatchScheduler : Scheduler</code>           \u2013            <p>Scheduler that updates hyperparameters after every batch.</p> </li> <li> <code>EpochScheduler : Scheduler</code>           \u2013            <p>Scheduler that updates hyperparameters after every epoch.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Using ParamScheduler with exponential scheduling\n&gt;&gt;&gt; scheduler = ParamScheduler('lr', exp_sched(1e-3, 1e-5))\n&gt;&gt;&gt; learner.add_callback(scheduler)\n</code></pre> <pre><code>&gt;&gt;&gt; # Using BatchScheduler with PyTorch's OneCycleLR\n&gt;&gt;&gt; from torch.optim.lr_scheduler import OneCycleLR\n&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; scheduler = BatchScheduler(partial(OneCycleLR, max_lr=1e-2, total_steps=1000))\n&gt;&gt;&gt; learner.add_callback(scheduler)\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.BatchScheduler","title":"<code>BatchScheduler</code>","text":"<p>               Bases: <code>Scheduler</code></p> <p>Scheduler that updates hyperparameters after every batch.</p> <p>This scheduler applies the hyperparameter updates after each batch during training, which is useful for schedulers that need frequent updates like OneCycleLR.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from torch.optim.lr_scheduler import OneCycleLR\n&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; scheduler = BatchScheduler(partial(OneCycleLR, max_lr=1e-2, total_steps=1000))\n&gt;&gt;&gt; learner.add_callback(scheduler)\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.BatchScheduler.after_batch","title":"<code>after_batch()</code>","text":"<p>Update hyperparameters after each batch during training.</p> <p>Only updates values during training mode, not during validation.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.EpochScheduler","title":"<code>EpochScheduler</code>","text":"<p>               Bases: <code>Scheduler</code></p> <p>Scheduler that updates hyperparameters after every epoch.</p> <p>This scheduler applies the hyperparameter updates after each epoch during training, which is useful for schedulers that need less frequent updates like StepLR or ReduceLROnPlateau.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from torch.optim.lr_scheduler import StepLR\n&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; scheduler = EpochScheduler(partial(StepLR, step_size=30, gamma=0.1))\n&gt;&gt;&gt; learner.add_callback(scheduler)\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.EpochScheduler.after_epoch","title":"<code>after_epoch()</code>","text":"<p>Update hyperparameters after each epoch during training.</p> <p>Only updates values during training mode, not during validation.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.ParamScheduler","title":"<code>ParamScheduler</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to schedule hyperparameter values during training.</p> <p>This class is used to schedule the values of hyperparameters (such as learning rate) during the training process. It can handle different schedulers for different parameter groups in the optimizer.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>The order in which this callback should be executed (default: 60).</p> </li> <li> <code>pname</code>               (<code>str</code>)           \u2013            <p>The name of the hyperparameter to be scheduled.</p> </li> <li> <code>sched_funcs</code>               (<code>list[Callable] | tuple[Callable]</code>)           \u2013            <p>List or tuple of scheduler functions for each parameter group.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Schedule learning rate with exponential decay\n&gt;&gt;&gt; scheduler = ParamScheduler('lr', exp_sched(0.01, 0.001))\n&gt;&gt;&gt; learner.add_callback(scheduler)\n</code></pre> <pre><code>&gt;&gt;&gt; # Different schedulers for different parameter groups\n&gt;&gt;&gt; schedulers = [lin_sched(0.01, 0.001), cos_sched(0.005, 0.0005)]\n&gt;&gt;&gt; scheduler = ParamScheduler('lr', schedulers)\n&gt;&gt;&gt; learner.add_callback(scheduler)\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.ParamScheduler.__init__","title":"<code>__init__(pname, sched_funcs)</code>","text":"<p>Initialize the parameter scheduler.</p> <p>Parameters:</p> <ul> <li> <code>pname</code>               (<code>str</code>)           \u2013            <p>The name of the hyperparameter to be scheduled (e.g., 'lr' for learning rate).</p> </li> <li> <code>sched_funcs</code>               (<code>list[Callable] | tuple[Callable]</code>)           \u2013            <p>A list or tuple of schedulers for each parameter group. Each scheduler should accept a single argument (position) and return a value for the hyperparameter. If a single scheduler is provided, it will be applied to all parameter groups.</p> </li> </ul>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.ParamScheduler.before_batch","title":"<code>before_batch()</code>","text":"<p>Update hyperparameter values before each batch during training.</p> <p>Only updates values during training mode, not during validation.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.ParamScheduler.before_fit","title":"<code>before_fit()</code>","text":"<p>Prepare the scheduler before training begins.</p> <p>If a single scheduler function is provided, it will be replicated for all parameter groups in the optimizer.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.Scheduler","title":"<code>Scheduler</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Base scheduler to change hyperparameters using PyTorch schedulers.</p> <p>This class provides a base implementation for using PyTorch's built-in schedulers. PyTorch's schedulers take the optimizer as the first argument, so it's important to pass a scheduler that has all its arguments already passed except the optimizer.</p> <p>Attributes:</p> <ul> <li> <code>scheduler</code>               (<code>Callable</code>)           \u2013            <p>The scheduler function to be used.</p> </li> <li> <code>scheduler_object</code>               (<code>_LRScheduler</code>)           \u2013            <p>The instantiated scheduler object.</p> </li> </ul> Notes <p>PyTorch's schedulers take optimizer as the first argument. Therefore, it is important to pass the scheduler that has all its arguments already passed except the optimizer. This will be done in <code>Scheduler</code>'s <code>before_fit</code> method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from torch.optim.lr_scheduler import OneCycleLR\n&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; scheduler = Scheduler(partial(OneCycleLR, max_lr=1e-2, total_steps=1000))\n&gt;&gt;&gt; learner.add_callback(scheduler)\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.Scheduler.__init__","title":"<code>__init__(scheduler)</code>","text":"<p>Initialize the scheduler.</p> <p>Parameters:</p> <ul> <li> <code>scheduler</code>               (<code>Callable</code>)           \u2013            <p>The scheduler function to be used. Should accept an optimizer as its first argument and return a scheduler object.</p> </li> </ul>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.Scheduler.before_fit","title":"<code>before_fit()</code>","text":"<p>Create the scheduler object before training begins.</p> <p>Instantiates the scheduler with the current optimizer.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.Scheduler.step","title":"<code>step()</code>","text":"<p>Step the scheduler to update hyperparameter values.</p> <p>This method calls the step method of the underlying PyTorch scheduler.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.annealer","title":"<code>annealer(func)</code>","text":"<p>Decorator to create annealer functions.</p> <p>This decorator wraps a function to create a partial function that can be used as a scheduler. The wrapped function should accept start, end, and position parameters and return the scheduled value.</p> <p>Parameters:</p> <ul> <li> <code>func</code>               (<code>Callable</code>)           \u2013            <p>The function to be wrapped. Should have signature func(start, end, pos).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Callable</code>           \u2013            <p>A partial function that can be used as a scheduler.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @annealer\n&gt;&gt;&gt; def my_scheduler(start, end, pos):\n...     return start + (end - start) * pos\n&gt;&gt;&gt; scheduler = my_scheduler(0.1, 0.01)\n&gt;&gt;&gt; value = scheduler(0.5)  # pos = 0.5\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.combine_scheds","title":"<code>combine_scheds(pcts, scheds)</code>","text":"<p>Combine multiple schedulers, each running for a given percentage of training.</p> <p>Parameters:</p> <ul> <li> <code>pcts</code>               (<code>list[float]</code>)           \u2013            <p>List of percentages (should sum to 1.0) indicating how much of training each scheduler should run for.</p> </li> <li> <code>scheds</code>               (<code>list[Callable]</code>)           \u2013            <p>List of scheduler functions corresponding to each percentage.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Callable</code>           \u2013            <p>A combined scheduler function that switches between schedulers based on the current training position.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AssertionError</code>             \u2013            <p>If the number of percentages doesn't match the number of schedulers, if percentages don't sum to 1.0, or if any percentage is negative.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scheduler1 = lin_sched(0.01, 0.005)\n&gt;&gt;&gt; scheduler2 = cos_sched(0.005, 0.001)\n&gt;&gt;&gt; combined = combine_scheds([0.6, 0.4], [scheduler1, scheduler2])\n&gt;&gt;&gt; # First 60% of training uses linear scheduler, last 40% uses cosine\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.cos_1cycle_anneal","title":"<code>cos_1cycle_anneal(start, high, end)</code>","text":"<p>Combine two cosine schedulers for 1-cycle learning rate scheduling.</p> <p>Creates a list of two cosine schedulers where the first scheduler goes from <code>start</code> to <code>high</code> and the second scheduler goes from <code>high</code> to <code>end</code>.</p> <p>Parameters:</p> <ul> <li> <code>start</code>               (<code>float</code>)           \u2013            <p>The starting value.</p> </li> <li> <code>high</code>               (<code>float</code>)           \u2013            <p>The peak value in the middle of training.</p> </li> <li> <code>end</code>               (<code>float</code>)           \u2013            <p>The ending value.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>A list containing two cosine schedulers for the 1-cycle policy.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; schedulers = cos_1cycle_anneal(0.001, 0.01, 0.0001)\n&gt;&gt;&gt; len(schedulers)  # Returns 2 schedulers\n2\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.cos_sched","title":"<code>cos_sched(start, end, pos)</code>","text":"<p>Cosine scheduler that interpolates using cosine annealing.</p> <p>Parameters:</p> <ul> <li> <code>start</code>               (<code>float</code>)           \u2013            <p>The starting value.</p> </li> <li> <code>end</code>               (<code>float</code>)           \u2013            <p>The ending value.</p> </li> <li> <code>pos</code>               (<code>float</code>)           \u2013            <p>Current position in training (0 to 1).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The cosine-interpolated value.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scheduler = cos_sched(0.01, 0.001)\n&gt;&gt;&gt; scheduler(0.0)  # Returns start value\n0.01\n&gt;&gt;&gt; scheduler(1.0)  # Returns end value\n0.001\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.exp_sched","title":"<code>exp_sched(start, end, pos)</code>","text":"<p>Exponential scheduler that interpolates exponentially between start and end values.</p> <p>Parameters:</p> <ul> <li> <code>start</code>               (<code>float</code>)           \u2013            <p>The starting value.</p> </li> <li> <code>end</code>               (<code>float</code>)           \u2013            <p>The ending value.</p> </li> <li> <code>pos</code>               (<code>float</code>)           \u2013            <p>Current position in training (0 to 1).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The exponentially interpolated value.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scheduler = exp_sched(0.01, 0.001)\n&gt;&gt;&gt; scheduler(0.0)  # Returns start value\n0.01\n&gt;&gt;&gt; scheduler(1.0)  # Returns end value\n0.001\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.lin_sched","title":"<code>lin_sched(start, end, pos)</code>","text":"<p>Linear scheduler that interpolates linearly between start and end values.</p> <p>Parameters:</p> <ul> <li> <code>start</code>               (<code>float</code>)           \u2013            <p>The starting value.</p> </li> <li> <code>end</code>               (<code>float</code>)           \u2013            <p>The ending value.</p> </li> <li> <code>pos</code>               (<code>float</code>)           \u2013            <p>Current position in training (0 to 1).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The linearly interpolated value.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scheduler = lin_sched(0.01, 0.001)\n&gt;&gt;&gt; scheduler(0.5)  # Returns 0.0055 (halfway between 0.01 and 0.001)\n0.0055\n</code></pre>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.no_sched","title":"<code>no_sched(start, end, pos)</code>","text":"<p>Constant scheduler that returns the start value regardless of position.</p> <p>Parameters:</p> <ul> <li> <code>start</code>               (<code>float</code>)           \u2013            <p>The constant value to return.</p> </li> <li> <code>end</code>               (<code>float</code>)           \u2013            <p>Not used in this scheduler (kept for interface consistency).</p> </li> <li> <code>pos</code>               (<code>float</code>)           \u2013            <p>Current position in training (0 to 1). Not used in this scheduler.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The start value (constant).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scheduler = no_sched(0.01, 0.001)\n&gt;&gt;&gt; scheduler(0.5)  # Returns 0.01 regardless of position\n0.01\n</code></pre>"},{"location":"callbacks/training/","title":"Training","text":"<p>Training-related callbacks for customizing training and validation loops.</p> <p>This module provides a comprehensive collection of callbacks that enhance and customize the training process. These callbacks handle various aspects of training including device management, progress tracking, metrics computation, data augmentation, and learning rate optimization.</p> <p>The callbacks are designed to be easily composable and can be used together to create sophisticated training pipelines. Each callback has a specific execution order to ensure proper sequencing of operations.</p> <p>Classes:</p> <ul> <li> <code>DeviceCallback</code>           \u2013            <p>Move model and data to specified device (CPU/GPU).</p> </li> <li> <code>TrainEvalCallback</code>           \u2013            <p>Track training progress and manage training/evaluation modes.</p> </li> <li> <code>ProgressCallback</code>           \u2013            <p>Display progress bars and live loss plots during training.</p> </li> <li> <code>Recorder</code>           \u2013            <p>Record training metrics and optimizer parameters for analysis.</p> </li> <li> <code>ModelResetter</code>           \u2013            <p>Reset model parameters at various training stages.</p> </li> <li> <code>LRFinder</code>           \u2013            <p>Find optimal learning rate using exponential scheduling.</p> </li> <li> <code>BatchTransform</code>           \u2013            <p>Apply transformations to entire batches.</p> </li> <li> <code>BatchTransformX</code>           \u2013            <p>Apply transformations to input features only.</p> </li> <li> <code>SingleBatchCallback</code>           \u2013            <p>Run only one batch for debugging purposes.</p> </li> <li> <code>SingleBatchForwardCallback</code>           \u2013            <p>Run one batch and stop after forward pass.</p> </li> <li> <code>MetricsCallback</code>           \u2013            <p>Compute and log various metrics during training.</p> </li> <li> <code>Mixup</code>           \u2013            <p>Implement mixup data augmentation technique.</p> </li> </ul> <p>Examples:</p> <p>Basic training with device management and progress tracking:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.callbacks.training import DeviceCallback, ProgressCallback\n&gt;&gt;&gt; from cmn_ai.callbacks.training import TrainEvalCallback, Recorder\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create callbacks\n&gt;&gt;&gt; callbacks = [\n...     DeviceCallback(device='cuda'),  # Move to GPU\n...     TrainEvalCallback(),            # Track progress\n...     ProgressCallback(plot=True),    # Show progress bars\n...     Recorder('lr', 'momentum')      # Record learning rate and momentum\n... ]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Add to learner\n&gt;&gt;&gt; learner.add_cbs(callbacks)\n</code></pre> <p>Learning rate finding:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.callbacks.training import LRFinder\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Find optimal learning rate\n&gt;&gt;&gt; lr_finder = LRFinder(gamma=1.3, num_iter=100, stop_div=True)\n&gt;&gt;&gt; learner.add_cb(lr_finder)\n&gt;&gt;&gt; learner.fit(1)  # Run for 1 epoch\n&gt;&gt;&gt; lr_finder.recorder.plot()  # Plot lr vs loss\n</code></pre> <p>Data augmentation with mixup:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.callbacks.training import Mixup\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Add mixup augmentation\n&gt;&gt;&gt; mixup = Mixup(alpha=0.4)\n&gt;&gt;&gt; learner.add_cb(mixup)\n&gt;&gt;&gt; learner.fit(10)\n</code></pre> <p>Metrics tracking:</p> <pre><code>&gt;&gt;&gt; from torcheval.metrics import MulticlassAccuracy\n&gt;&gt;&gt; from cmn_ai.callbacks.training import MetricsCallback\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Track accuracy during training\n&gt;&gt;&gt; accuracy = MulticlassAccuracy()\n&gt;&gt;&gt; metrics_cb = MetricsCallback(accuracy=accuracy)\n&gt;&gt;&gt; learner.add_cb(metrics_cb)\n&gt;&gt;&gt; learner.fit(5)\n</code></pre> <p>Debugging with single batch:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.callbacks.training import SingleBatchCallback\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Run only one batch for debugging\n&gt;&gt;&gt; debug_cb = SingleBatchCallback()\n&gt;&gt;&gt; learner.add_cb(debug_cb)\n&gt;&gt;&gt; learner.fit(1)  # Will stop after first batch\n</code></pre> <p>Raises:</p> <ul> <li> <code>CancelFitException</code>             \u2013            <p>Stop training and move to after_fit.</p> </li> <li> <code>CancelEpochException</code>             \u2013            <p>Stop current epoch and move to after_epoch.</p> </li> <li> <code>CancelTrainException</code>             \u2013            <p>Stop training current epoch and move to after_train.</p> </li> <li> <code>CancelValidException</code>             \u2013            <p>Stop validation phase and move after_validate.</p> </li> <li> <code>CancelBatchException</code>             \u2013            <p>Stop current batch and move to after_batch.</p> </li> <li> <code>CancelStepException</code>             \u2013            <p>Skip stepping the optimizer.</p> </li> <li> <code>CancelBackwardException</code>             \u2013            <p>Skip the backward pass and move to after_backward.</p> </li> </ul> Notes <ul> <li>Callbacks are executed in order based on their <code>order</code> attribute</li> <li>Lower order numbers execute earlier</li> <li>Some callbacks modify the training loop behavior significantly</li> <li>Always test callbacks individually before combining them</li> <li>The <code>Recorder</code> callback is essential for post-training analysis</li> <li><code>LRFinder</code> should be used before full training to find optimal learning rate</li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransform","title":"<code>BatchTransform</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Apply transformations to entire batches before processing.</p> <p>This callback applies a transformation function to the entire batch before it's processed by the model. The transformation runs on the device where the data is located.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>Callback execution order (DeviceCallback.order + 1).</p> </li> <li> <code>tfm</code>               (<code>Callback</code>)           \u2013            <p>Transformation function to apply.</p> </li> <li> <code>on_train</code>               (<code>bool</code>)           \u2013            <p>Whether to apply transformation during training.</p> </li> <li> <code>on_valid</code>               (<code>bool</code>)           \u2013            <p>Whether to apply transformation during validation.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransform.__init__","title":"<code>__init__(tfm, on_train=True, on_valid=True)</code>","text":"<p>Initialize BatchTransform.</p> <p>Parameters:</p> <ul> <li> <code>tfm</code>               (<code>Callback</code>)           \u2013            <p>Transformation function to apply on the batch.</p> </li> <li> <code>on_train</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to apply the transformation during training.</p> </li> <li> <code>on_valid</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to apply the transformation during validation.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransform.before_batch","title":"<code>before_batch()</code>","text":"<p>Apply transformation to batch if conditions are met.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransformX","title":"<code>BatchTransformX</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Apply transformations to input features (X) only.</p> <p>This callback applies a transformation function specifically to the input features (X) of the batch, leaving the targets (Y) unchanged.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>Callback execution order (DeviceCallback.order + 1).</p> </li> <li> <code>tfm</code>               (<code>Callback</code>)           \u2013            <p>Transformation function to apply.</p> </li> <li> <code>on_train</code>               (<code>bool</code>)           \u2013            <p>Whether to apply transformation during training.</p> </li> <li> <code>on_valid</code>               (<code>bool</code>)           \u2013            <p>Whether to apply transformation during validation.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransformX.__init__","title":"<code>__init__(tfm, on_train=True, on_valid=True)</code>","text":"<p>Initialize BatchTransformX.</p> <p>Parameters:</p> <ul> <li> <code>tfm</code>               (<code>Callback</code>)           \u2013            <p>Transformation function to apply on the input features.</p> </li> <li> <code>on_train</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to apply the transformation during training.</p> </li> <li> <code>on_valid</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to apply the transformation during validation.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransformX.before_batch","title":"<code>before_batch()</code>","text":"<p>Apply transformation to input features if conditions are met.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.DeviceCallback","title":"<code>DeviceCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Move batch and model to specified device.</p> <p>This callback ensures that both the model and input data are moved to the specified device (CPU/GPU) before training begins.</p> <p>Attributes:</p> <ul> <li> <code>device</code>               (<code>str | device</code>)           \u2013            <p>Device to copy batch and model to.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.DeviceCallback.__init__","title":"<code>__init__(device=DEFAULT_DEVICE)</code>","text":"<p>Initialize DeviceCallback.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str | device</code>, default:                   <code>DEFAULT_DEVICE</code> )           \u2013            <p>Device to copy batch and model to.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.DeviceCallback.before_batch","title":"<code>before_batch()</code>","text":"<p>Move batch data to specified device before each batch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.DeviceCallback.before_fit","title":"<code>before_fit()</code>","text":"<p>Move model to specified device before training starts.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.LRFinder","title":"<code>LRFinder</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Find optimal learning rate using exponential schedule.</p> <p>This callback implements the learning rate finder technique from \"Cyclical Learning Rates for Training Neural Networks\". It tries different learning rates using an exponential schedule to help determine the best learning rate for training.</p> <p>Attributes:</p> <ul> <li> <code>gamma</code>               (<code>int</code>)           \u2013            <p>Multiplicative factor for learning rate increase.</p> </li> <li> <code>num_iter</code>               (<code>int</code>)           \u2013            <p>Number of iterations to run the training.</p> </li> <li> <code>stop_div</code>               (<code>bool</code>)           \u2013            <p>Whether to stop training if loss diverges.</p> </li> <li> <code>max_mult</code>               (<code>int</code>)           \u2013            <p>Divergence threshold multiplier.</p> </li> <li> <code>scheduler</code>               (<code>ExponentialLR</code>)           \u2013            <p>Learning rate scheduler.</p> </li> <li> <code>best_loss</code>               (<code>float</code>)           \u2013            <p>Best loss encountered during training.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.LRFinder.__init__","title":"<code>__init__(gamma=1.3, num_iter=100, stop_div=True, max_mult=4)</code>","text":"<p>Initialize LRFinder.</p> <p>Parameters:</p> <ul> <li> <code>gamma</code>               (<code>int</code>, default:                   <code>1.3</code> )           \u2013            <p>Multiplicative factor for learning rate increase.</p> </li> <li> <code>num_iter</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Number of iterations to run the training.</p> </li> <li> <code>stop_div</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to stop training if loss diverges (loss &gt; 4 * best_loss).</p> </li> <li> <code>max_mult</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>Divergence threshold. If loss &gt;= max_mult * minimum loss, stop training.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.LRFinder.after_batch","title":"<code>after_batch()</code>","text":"<p>Update best loss and check for divergence or completion.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.LRFinder.after_fit","title":"<code>after_fit()</code>","text":"<p>Restore model state and plot learning rate vs loss.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.LRFinder.before_fit","title":"<code>before_fit()</code>","text":"<p>Set up learning rate scheduler and save initial model state.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.LRFinder.before_validate","title":"<code>before_validate()</code>","text":"<p>Skip validation during learning rate finding.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback","title":"<code>MetricsCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Compute and log metrics during training and validation.</p> <p>This callback computes various metrics after each training/validation epoch and logs them using the learner's logger. Metrics must implement <code>reset</code> and <code>compute</code> methods. It's recommended to use metrics from the <code>torcheval</code> package or inherit from its Metrics base class.</p> <p>Attributes:</p> <ul> <li> <code>metrics</code>               (<code>dict[str, Any]</code>)           \u2013            <p>Dictionary of named metrics to compute.</p> </li> <li> <code>all_metrics</code>               (<code>dict[str, Any]</code>)           \u2013            <p>All metrics including loss metric.</p> </li> <li> <code>stats</code>               (<code>list[str]</code>)           \u2013            <p>Current statistics to log.</p> </li> <li> <code>start_time</code>               (<code>float</code>)           \u2013            <p>Start time for timing calculations.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback.__init__","title":"<code>__init__(*metrics, **named_metrics)</code>","text":"<p>Initialize MetricsCallback.</p> <p>Parameters:</p> <ul> <li> <code>*metrics</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>Positional metrics to add.</p> </li> <li> <code>**named_metrics</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Named metrics to add.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback.after_batch","title":"<code>after_batch()</code>","text":"<p>Update metrics with batch predictions and targets.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback.after_train","title":"<code>after_train()</code>","text":"<p>Compute and log metrics after training epoch.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Logged statistics string.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback.after_validate","title":"<code>after_validate()</code>","text":"<p>Compute and log metrics after validation epoch.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Logged statistics string.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback.before_fit","title":"<code>before_fit()</code>","text":"<p>Log metric names as header before training starts.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Header string with metric names.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback.before_train","title":"<code>before_train()</code>","text":"<p>Reset metrics before training phase.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback.before_validate","title":"<code>before_validate()</code>","text":"<p>Reset metrics before validation phase.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup","title":"<code>Mixup</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Implement mixup data augmentation technique.</p> <p>This callback implements the mixup technique where instead of feeding raw data to the model, it uses linear combinations of inputs using alpha from a beta distribution. The labels are also linear combinations of the original labels. Based on the paper \"mixup: BEYOND EMPIRICAL RISK MINIMIZATION\".</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>Callback execution order (90).</p> </li> <li> <code>alpha</code>               (<code>float</code>)           \u2013            <p>Concentration parameter for Beta distribution.</p> </li> <li> <code>distrib</code>               (<code>Beta</code>)           \u2013            <p>Beta distribution for sampling mixup weights.</p> </li> <li> <code>old_loss_func</code>               (<code>Callable</code>)           \u2013            <p>Original loss function before mixup.</p> </li> <li> <code>\u03bb</code>               (<code>Tensor</code>)           \u2013            <p>Mixup weight for current batch.</p> </li> <li> <code>yb1</code>               (<code>List[Tensor]</code>)           \u2013            <p>Shuffled targets for mixup.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup.__init__","title":"<code>__init__(alpha=0.4)</code>","text":"<p>Initialize Mixup.</p> <p>Parameters:</p> <ul> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>0.4</code> )           \u2013            <p>Concentration parameter for Beta distribution.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup.after_fit","title":"<code>after_fit()</code>","text":"<p>Restore original loss function after training ends.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup.before_batch","title":"<code>before_batch()</code>","text":"<p>Apply mixup transformation to batch inputs and targets.</p> <p>The mixup process involves: 1. Drawing samples from a beta distribution for each image 2. Taking the maximum of \u03bb and 1-\u03bb to avoid identical combinations 3. Shuffling the batch for combination 4. Creating linear combinations of inputs and targets</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup.before_fit","title":"<code>before_fit()</code>","text":"<p>Store original loss function before training starts.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup.loss_func","title":"<code>loss_func(pred, yb)</code>","text":"<p>Compute mixup loss combining original and shuffled targets.</p> <p>Parameters:</p> <ul> <li> <code>pred</code>               (<code>Tensor</code>)           \u2013            <p>Model predictions.</p> </li> <li> <code>yb</code>               (<code>Tensor</code>)           \u2013            <p>Original targets.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>           \u2013            <p>Mixup loss value.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ModelResetter","title":"<code>ModelResetter</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Reset model parameters at various training stages.</p> <p>This callback is particularly useful for NLP models that need to reset hidden states. It assumes the model has a <code>reset</code> method that knows which parameters to reset and how.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ModelResetter.after_fit","title":"<code>after_fit()</code>","text":"<p>Reset model after training ends.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ModelResetter.before_train","title":"<code>before_train()</code>","text":"<p>Reset model before training phase.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ModelResetter.before_validate","title":"<code>before_validate()</code>","text":"<p>Reset model before validation phase.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback","title":"<code>ProgressCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Track training progress with progress bars and live loss plotting.</p> <p>This callback provides visual feedback during training by displaying progress bars and optionally plotting training and validation losses in real-time.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>Callback execution order (-20).</p> </li> <li> <code>plot</code>               (<code>bool</code>)           \u2013            <p>Whether to plot train/valid losses during training.</p> </li> <li> <code>train_losses</code>               (<code>List[float]</code>)           \u2013            <p>List of training losses for plotting.</p> </li> <li> <code>valid_losses</code>               (<code>List[float]</code>)           \u2013            <p>List of validation losses for plotting.</p> </li> <li> <code>mbar</code>               (<code>master_bar</code>)           \u2013            <p>Master progress bar for epochs.</p> </li> <li> <code>pb</code>               (<code>progress_bar</code>)           \u2013            <p>Progress bar for batches.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.__init__","title":"<code>__init__(plot=True)</code>","text":"<p>Initialize ProgressCallback.</p> <p>Parameters:</p> <ul> <li> <code>plot</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to plot train/valid losses during training.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.after_batch","title":"<code>after_batch()</code>","text":"<p>Update progress bar and optionally plot losses after each batch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.after_epoch","title":"<code>after_epoch()</code>","text":"<p>Update validation loss plot after each epoch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.after_fit","title":"<code>after_fit()</code>","text":"<p>Clean up progress bar after training ends.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.before_fit","title":"<code>before_fit()</code>","text":"<p>Initialize progress tracking and create progress bars.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.before_train","title":"<code>before_train()</code>","text":"<p>Set up progress bar before training phase.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.before_validate","title":"<code>before_validate()</code>","text":"<p>Set up progress bar before validation phase.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.set_pb","title":"<code>set_pb()</code>","text":"<p>Create and configure progress bar for current phase.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder","title":"<code>Recorder</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Record training metrics and optimizer parameters for later analysis.</p> <p>This callback keeps track of losses and optimizer parameters (like learning rates) throughout training, enabling post-training analysis and visualization.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>Callback execution order (50).</p> </li> <li> <code>params</code>               (<code>List[str]</code>)           \u2013            <p>List of parameter names to track.</p> </li> <li> <code>params_records</code>               (<code>Dict[str, List[List[float]]]</code>)           \u2013            <p>Recorded parameter values for each parameter group.</p> </li> <li> <code>losses</code>               (<code>List[float]</code>)           \u2013            <p>Recorded training losses.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.__init__","title":"<code>__init__(*params)</code>","text":"<p>Initialize Recorder.</p> <p>Parameters:</p> <ul> <li> <code>*params</code>               (<code>tuple[str, ...]</code>, default:                   <code>()</code> )           \u2013            <p>Parameter names to track (e.g., 'lr', 'momentum').</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.after_batch","title":"<code>after_batch()</code>","text":"<p>Record parameters and loss after each training batch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.before_fit","title":"<code>before_fit()</code>","text":"<p>Initialize recording structures before training starts.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.plot","title":"<code>plot(pgid=-1, skip_last=0)</code>","text":"<p>Plot loss vs learning rate (log-scale).</p> <p>Parameters:</p> <ul> <li> <code>pgid</code>               (<code>int</code>, default:                   <code>-1</code> )           \u2013            <p>Parameter group index to plot.</p> </li> <li> <code>skip_last</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Number of last losses to skip in plotting.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.plot_loss","title":"<code>plot_loss(skip_last=0)</code>","text":"<p>Plot training losses.</p> <p>Parameters:</p> <ul> <li> <code>skip_last</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Number of last losses to skip in plotting.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.plot_params","title":"<code>plot_params(params='lr', pgid=-1, figsize=(8, 6))</code>","text":"<p>Plot parameter values across training iterations.</p> <p>Parameters:</p> <ul> <li> <code>params</code>               (<code>str | Iterable[str]</code>, default:                   <code>\"lr\"</code> )           \u2013            <p>Parameter name(s) to plot.</p> </li> <li> <code>pgid</code>               (<code>int</code>, default:                   <code>-1</code> )           \u2013            <p>Parameter group index to plot.</p> </li> <li> <code>figsize</code>               (<code>tuple[int, int]</code>, default:                   <code>(8, 6)</code> )           \u2013            <p>Figure size for the plot.</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.SingleBatchCallback","title":"<code>SingleBatchCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Run only one training/validation batch and stop.</p> <p>This callback is useful for debugging or when you want to check parameters after processing just one batch. It raises CancelFitException after the first batch to stop training.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>Callback execution order (1).</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.SingleBatchCallback.after_batch","title":"<code>after_batch()</code>","text":"<p>Stop training after the first batch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.SingleBatchForwardCallback","title":"<code>SingleBatchForwardCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Run one batch and stop after forward pass.</p> <p>This callback runs one training/validation batch and stops after computing the loss (after forward pass) by raising CancelFitException. Useful for debugging or checking parameters after one forward pass.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>Callback execution order (1).</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.SingleBatchForwardCallback.after_loss","title":"<code>after_loss()</code>","text":"<p>Stop training after computing loss for the first batch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.TrainEvalCallback","title":"<code>TrainEvalCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Track training progress and manage training/evaluation modes.</p> <p>This callback tracks the number of iterations, percentage of training completed, and sets the appropriate training or evaluation mode for the model.</p> <p>Attributes:</p> <ul> <li> <code>order</code>               (<code>int</code>)           \u2013            <p>Callback execution order (-10).</p> </li> </ul>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.TrainEvalCallback.after_batch","title":"<code>after_batch()</code>","text":"<p>Update iteration counter and training percentage after each batch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.TrainEvalCallback.before_fit","title":"<code>before_fit()</code>","text":"<p>Initialize training counters before training starts.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.TrainEvalCallback.before_train","title":"<code>before_train()</code>","text":"<p>Set model to training mode and update training percentage.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.TrainEvalCallback.before_validate","title":"<code>before_validate()</code>","text":"<p>Set model to evaluation mode before validation.</p>"},{"location":"tabular/data/","title":"Data","text":"<p>Tabular data manipulation and splitting utilities.</p> <p>This module provides advanced data splitting functionality for tabular datasets, with support for stratified splitting, group-aware splitting, and automatic validation of class distribution requirements.</p> <p>Classes:</p> <ul> <li> <code>DataSplitter : class</code>           \u2013            <p>A configurable data splitter with support for train/validation/test splits, stratification, group-aware splitting, and automatic size adjustment.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>get_data_splits : function</code>             \u2013              <p>Convenience function for one-time data splitting operations.</p> </li> <li> <code>_suggest_sizes : function</code>             \u2013              <p>Internal utility for adjusting split sizes to ensure stratification feasibility.</p> </li> </ul> Notes <p>The module is designed to handle common challenges in machine learning data preparation, including:</p> <ul> <li>Ensuring all classes have sufficient samples in each split</li> <li>Automatic size adjustment when requested splits are infeasible</li> <li>Group-aware splitting to prevent data leakage</li> <li>Comprehensive validation with helpful error messages</li> </ul> <p>The splitting functions are compatible with both NumPy arrays and pandas DataFrames, making them suitable for various data science workflows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from cmn_ai.tabular.data import get_data_splits\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create sample data\n&gt;&gt;&gt; X = pd.DataFrame({'feature1': range(100), 'feature2': range(100, 200)})\n&gt;&gt;&gt; y = np.random.choice(['A', 'B', 'C'], size=100)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Basic stratified split\n&gt;&gt;&gt; X_train, X_val, X_test, y_train, y_val, y_test = get_data_splits(\n...     X, y, train_size=0.7, val_size=0.15, test_size=0.15\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Group-aware splitting\n&gt;&gt;&gt; groups = np.random.choice(['group1', 'group2', 'group3'], size=100)\n&gt;&gt;&gt; splits = get_data_splits(X, y, groups=groups, stratify=False)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Using DataSplitter for repeated operations\n&gt;&gt;&gt; splitter = DataSplitter(train_size=0.8, val_size=0.1, test_size=0.1)\n&gt;&gt;&gt; splits1 = splitter.split(X1, y1)\n&gt;&gt;&gt; splits2 = splitter.split(X2, y2)\n</code></pre>"},{"location":"tabular/data/#cmn_ai.tabular.data.DataSplitter","title":"<code>DataSplitter</code>","text":"<p>Advanced data splitter for train/validation/test sets with stratification support.</p> <p>This class provides a comprehensive solution for splitting tabular datasets with support for stratified splitting, group-aware splitting, automatic size adjustment, and validation of class distribution requirements. Designed for reusable splitting configurations across multiple datasets.</p> <p>Parameters:</p> <ul> <li> <code>train_size</code>               (<code>float</code>, default:                   <code>0.7</code> )           \u2013            <p>Fraction of data for training set (0 &lt; train_size &lt; 1).</p> </li> <li> <code>val_size</code>               (<code>float</code>, default:                   <code>0.15</code> )           \u2013            <p>Fraction of data for validation set (0 &lt; val_size &lt; 1).</p> </li> <li> <code>test_size</code>               (<code>float</code>, default:                   <code>0.15</code> )           \u2013            <p>Fraction of data for test set (0 &lt; test_size &lt; 1). train_size + val_size + test_size must equal 1.0.</p> </li> <li> <code>stratify</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to preserve class proportions in each split. Incompatible with group-aware splitting.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to shuffle data before splitting.</p> </li> <li> <code>random_state</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Random seed for reproducible splits.</p> </li> <li> <code>min_class_count_check</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to validate that all classes have sufficient samples for the requested split sizes with automatic adjustment suggestions.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>train_size</code>               (<code>float</code>)           \u2013            <p>Configured training set fraction.</p> </li> <li> <code>val_size</code>               (<code>float</code>)           \u2013            <p>Configured validation set fraction.</p> </li> <li> <code>test_size</code>               (<code>float</code>)           \u2013            <p>Configured test set fraction.</p> </li> <li> <code>stratify</code>               (<code>bool</code>)           \u2013            <p>Configured stratification setting.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>)           \u2013            <p>Configured shuffle setting.</p> </li> <li> <code>random_state</code>               (<code>int or None</code>)           \u2013            <p>Configured random state.</p> </li> <li> <code>min_class_count_check</code>               (<code>bool</code>)           \u2013            <p>Configured class count validation setting.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>split</code>             \u2013              <p>Split data into train/validation/test sets with optional parameter overrides.</p> </li> </ul> Notes <p>The DataSplitter is designed to handle several common challenges in ML data preparation:</p> <ul> <li>Class imbalance: Automatically detects when requested split sizes would   result in missing classes and suggests minimal adjustments.</li> <li>Group leakage: Supports group-aware splitting to prevent data leakage   when samples are not independent (e.g., time series, grouped data).</li> <li>Flexibility: Allows parameter overrides per split operation while   maintaining default configuration.</li> <li>Validation: Comprehensive input validation with informative error messages.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Basic usage with default settings\n&gt;&gt;&gt; splitter = DataSplitter()\n&gt;&gt;&gt; X = pd.DataFrame({'feature': range(100)})\n&gt;&gt;&gt; y = np.random.choice(['A', 'B', 'C'], 100)\n&gt;&gt;&gt; X_train, X_val, X_test, y_train, y_val, y_test = splitter.split(X, y)\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom configuration for imbalanced data\n&gt;&gt;&gt; splitter = DataSplitter(\n...     train_size=0.8, val_size=0.1, test_size=0.1,\n...     stratify=True, random_state=42\n... )\n&gt;&gt;&gt; splits = splitter.split(X, y)\n</code></pre> <pre><code>&gt;&gt;&gt; # Group-aware splitting for time series\n&gt;&gt;&gt; groups = np.repeat(range(10), 10)  # 10 groups of 10 samples each\n&gt;&gt;&gt; splits = splitter.split(X, y, groups=groups, stratify=False)\n</code></pre> <pre><code>&gt;&gt;&gt; # Parameter override for specific split\n&gt;&gt;&gt; splits = splitter.split(X, y, train_size=0.9, val_size=0.05, test_size=0.05)\n</code></pre>"},{"location":"tabular/data/#cmn_ai.tabular.data.DataSplitter.__init__","title":"<code>__init__(train_size=0.7, val_size=0.15, test_size=0.15, stratify=True, shuffle=True, random_state=None, min_class_count_check=True)</code>","text":"<p>Initialize DataSplitter with configuration for train/validation/test splitting.</p> <p>Parameters:</p> <ul> <li> <code>train_size</code>               (<code>float</code>, default:                   <code>0.7</code> )           \u2013            <p>Fraction of data allocated to training set. Must be in range (0, 1). Combined with val_size and test_size must sum to 1.0.</p> </li> <li> <code>val_size</code>               (<code>float</code>, default:                   <code>0.15</code> )           \u2013            <p>Fraction of data allocated to validation set. Must be in range (0, 1). Can be set to None to auto-infer from train_size and test_size.</p> </li> <li> <code>test_size</code>               (<code>float</code>, default:                   <code>0.15</code> )           \u2013            <p>Fraction of data allocated to test set. Must be in range (0, 1). Can be set to None to auto-infer from train_size and val_size.</p> </li> <li> <code>stratify</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to preserve class distribution proportions across splits. When True, each split will maintain approximately the same class ratios as the original dataset. Not compatible with group-based splitting.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to shuffle the data before splitting. Recommended for most use cases unless data order is important (e.g., time series).</p> </li> <li> <code>random_state</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random number generator to ensure reproducible splits. If None, splits will be different each time.</p> </li> <li> <code>min_class_count_check</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to validate that each class has sufficient samples for the requested split sizes. When True, will automatically suggest adjusted sizes if stratification would fail due to insufficient samples in rare classes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If train_size + val_size + test_size != 1.0 (after auto-inference). If any size parameter is not in range (0, 1). If stratify=True but target has insufficient samples per class.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Standard 70/15/15 split with stratification\n&gt;&gt;&gt; splitter = DataSplitter()\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom proportions for small datasets\n&gt;&gt;&gt; splitter = DataSplitter(\n...     train_size=0.6, val_size=0.2, test_size=0.2,\n...     random_state=42\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Non-stratified splitting for regression or grouped data\n&gt;&gt;&gt; splitter = DataSplitter(stratify=False, shuffle=True)\n</code></pre> <pre><code>&gt;&gt;&gt; # Disable class count validation for advanced use cases\n&gt;&gt;&gt; splitter = DataSplitter(min_class_count_check=False)\n</code></pre>"},{"location":"tabular/data/#cmn_ai.tabular.data.DataSplitter.split","title":"<code>split(X, y=None, *, train_size=None, val_size=None, test_size=None, stratify=None, shuffle=None, random_state=None, return_indices=False, groups=None, min_class_count_check=None)</code>","text":"<p>Split data into train, validation, and test sets with optional parameter overrides.</p> <p>This method applies the configured splitting strategy to the provided data, with options to override instance defaults for specific operations. Supports both stratified and group-aware splitting with automatic validation.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>array-like of shape (n_samples, n_features)</code>)           \u2013            <p>Feature matrix to split. Accepts NumPy arrays, pandas DataFrames, or other array-like structures with indexing support.</p> </li> <li> <code>y</code>               (<code>array-like of shape (n_samples,)</code>, default:                   <code>None</code> )           \u2013            <p>Target vector for supervised learning. Required for stratified splitting. Accepts NumPy arrays, pandas Series, or lists.</p> </li> <li> <code>train_size</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>Override instance train_size for this split operation. Must be in range (0, 1) and sum with val_size and test_size to 1.0.</p> </li> <li> <code>val_size</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>Override instance val_size for this split operation. Can be None to auto-infer from other sizes.</p> </li> <li> <code>test_size</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>Override instance test_size for this split operation. Can be None to auto-infer from other sizes.</p> </li> <li> <code>stratify</code>               (<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>Override instance stratify setting. If True, maintains class proportions across splits. Cannot be used with groups parameter.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>Override instance shuffle setting. Whether to shuffle data before splitting.</p> </li> <li> <code>random_state</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Override instance random_state for this operation. Ensures reproducible splits when provided.</p> </li> <li> <code>return_indices</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, returns indices of split samples instead of the data itself. Useful for custom data handling or debugging.</p> </li> <li> <code>groups</code>               (<code>array-like of shape (n_samples,)</code>, default:                   <code>None</code> )           \u2013            <p>Group labels for group-aware splitting. When provided, ensures samples from the same group don't appear in different splits. Automatically disables stratification.</p> </li> <li> <code>min_class_count_check</code>               (<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>Override instance min_class_count_check setting. Whether to validate class distribution feasibility and suggest adjustments if needed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple of arrays or indices</code>           \u2013            <p>If return_indices=False (default):     (X_train, X_val, X_test, y_train, y_val, y_test) if y is provided     (X_train, X_val, X_test) if y is None If return_indices=True:     (train_indices, val_indices, test_indices) as NumPy arrays</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If split sizes don't sum to 1.0 after inference. If stratification is requested but infeasible due to class distribution. If groups is provided together with stratify=True. If X and y have different lengths.</p> </li> <li> <code>UserWarning</code>             \u2013            <p>When classes barely meet minimum sample requirements for stratification.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; splitter = DataSplitter(train_size=0.7, val_size=0.15, test_size=0.15)\n</code></pre> <pre><code>&gt;&gt;&gt; # Basic stratified split\n&gt;&gt;&gt; X = pd.DataFrame({'feature': range(100)})\n&gt;&gt;&gt; y = np.random.choice(['A', 'B', 'C'], 100)\n&gt;&gt;&gt; X_train, X_val, X_test, y_train, y_val, y_test = splitter.split(X, y)\n</code></pre> <pre><code>&gt;&gt;&gt; # Override parameters for specific split\n&gt;&gt;&gt; X_train, X_val, X_test, y_train, y_val, y_test = splitter.split(\n...     X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Group-aware splitting\n&gt;&gt;&gt; groups = np.repeat(range(10), 10)  # 10 groups of 10 samples each\n&gt;&gt;&gt; splits = splitter.split(X, y, groups=groups, stratify=False)\n</code></pre> <pre><code>&gt;&gt;&gt; # Return indices instead of data\n&gt;&gt;&gt; train_idx, val_idx, test_idx = splitter.split(\n...     X, y, return_indices=True\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Unsupervised data (no y)\n&gt;&gt;&gt; X_train, X_val, X_test = splitter.split(X)\n</code></pre>"},{"location":"tabular/data/#cmn_ai.tabular.data.get_data_splits","title":"<code>get_data_splits(X, y=None, *, train_size=0.7, val_size=0.15, test_size=0.15, stratify=True, shuffle=True, random_state=None, return_indices=False, groups=None, min_class_count_check=True)</code>","text":"<p>Convenient one-call function for train/validation/test data splitting.</p> <p>This function provides a simple interface for splitting datasets with advanced features including stratification, group-aware splitting, automatic class distribution validation, and size adjustment suggestions. For multiple split operations on different datasets, consider using DataSplitter directly for better performance.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>array-like of shape (n_samples, n_features)</code>)           \u2013            <p>Feature matrix to split. Supports NumPy arrays, pandas DataFrames, or any array-like structure with indexing capabilities.</p> </li> <li> <code>y</code>               (<code>array-like of shape (n_samples,)</code>, default:                   <code>None</code> )           \u2013            <p>Target vector for supervised learning. Required when stratify=True. Supports NumPy arrays, pandas Series, or lists.</p> </li> <li> <code>train_size</code>               (<code>float</code>, default:                   <code>0.7</code> )           \u2013            <p>Proportion of data allocated to training set. Must be in range (0, 1). Combined with val_size and test_size must sum to 1.0.</p> </li> <li> <code>val_size</code>               (<code>float</code>, default:                   <code>0.15</code> )           \u2013            <p>Proportion of data allocated to validation set. Must be in range (0, 1). Can be None to auto-infer from train_size and test_size.</p> </li> <li> <code>test_size</code>               (<code>float</code>, default:                   <code>0.15</code> )           \u2013            <p>Proportion of data allocated to test set. Must be in range (0, 1). Can be None to auto-infer from train_size and val_size.</p> </li> <li> <code>stratify</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to preserve class distribution proportions across all splits. When True, each split maintains approximately the same class ratios as the original dataset. Automatically disabled when groups is provided.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to shuffle data before splitting. Recommended for most use cases except when sample order is meaningful (e.g., time series data).</p> </li> <li> <code>random_state</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Seed for random number generator to ensure reproducible splits. If None, results will vary between calls.</p> </li> <li> <code>return_indices</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, returns sample indices instead of actual data splits. Useful for custom data handling or when working with complex data structures.</p> </li> <li> <code>groups</code>               (<code>array-like of shape (n_samples,)</code>, default:                   <code>None</code> )           \u2013            <p>Group labels for group-aware splitting. When provided, ensures that samples with the same group label don't appear across different splits, preventing data leakage in grouped data scenarios.</p> </li> <li> <code>min_class_count_check</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to validate class distribution feasibility for stratified splitting. When True, automatically suggests adjusted split sizes if any class has insufficient samples for the requested proportions.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple of arrays or indices</code>           \u2013            <p>If return_indices=False (default):     For supervised data (y provided):         (X_train, X_val, X_test, y_train, y_val, y_test)     For unsupervised data (y=None):         (X_train, X_val, X_test) If return_indices=True:     (train_indices, val_indices, test_indices) as NumPy arrays</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If train_size + val_size + test_size != 1.0 (after auto-inference). If any size parameter is not in range (0, 1). If stratify=True but insufficient samples per class for requested splits. If groups is provided together with stratify=True. If X and y have mismatched lengths.</p> </li> <li> <code>UserWarning</code>             \u2013            <p>When classes barely meet minimum requirements for stratified splitting.</p> </li> </ul> See Also <p>DataSplitter : Class-based interface for repeated splitting operations. sklearn.model_selection.train_test_split : Scikit-learn's 2-way splitting function.</p> Notes <p>This function internally creates a DataSplitter instance and calls its split() method. For applications requiring multiple split operations with the same configuration, using DataSplitter directly is more efficient as it avoids repeated parameter validation and object instantiation.</p> <p>The stratification algorithm ensures that rare classes are handled gracefully by automatically suggesting feasible split sizes when the requested proportions would result in empty classes in some splits.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from cmn_ai.tabular.data import get_data_splits\n</code></pre> <pre><code>&gt;&gt;&gt; # Basic stratified splitting\n&gt;&gt;&gt; X = pd.DataFrame({'feature1': range(100), 'feature2': range(100, 200)})\n&gt;&gt;&gt; y = np.random.choice(['A', 'B', 'C'], size=100)\n&gt;&gt;&gt; X_train, X_val, X_test, y_train, y_val, y_test = get_data_splits(X, y)\n&gt;&gt;&gt; print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\nTrain: 70, Val: 15, Test: 15\n</code></pre> <pre><code>&gt;&gt;&gt; # Custom proportions with reproducible results\n&gt;&gt;&gt; splits = get_data_splits(\n...     X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Group-aware splitting for time series or clustered data\n&gt;&gt;&gt; groups = np.repeat(range(20), 5)  # 20 groups of 5 samples each\n&gt;&gt;&gt; X_train, X_val, X_test, y_train, y_val, y_test = get_data_splits(\n...     X, y, groups=groups, stratify=False\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Unsupervised data splitting\n&gt;&gt;&gt; X_train, X_val, X_test = get_data_splits(X, shuffle=True, random_state=123)\n</code></pre> <pre><code>&gt;&gt;&gt; # Get indices for custom data handling\n&gt;&gt;&gt; train_idx, val_idx, test_idx = get_data_splits(\n...     X, y, return_indices=True, random_state=456\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Handle imbalanced data with automatic size adjustment\n&gt;&gt;&gt; y_imbalanced = np.array(['rare'] * 2 + ['common'] * 98)\n&gt;&gt;&gt; try:\n...     splits = get_data_splits(X, y_imbalanced)\n... except ValueError as e:\n...     print(\"Automatic suggestion provided:\", str(e))\n</code></pre>"},{"location":"tabular/eda/","title":"EDA","text":"<p>Exploratory Data Analysis (EDA) utilities for tabular data.</p> <p>This module provides comprehensive tools for exploratory data analysis on tabular datasets. It includes functions for data quality assessment, statistical analysis, correlation analysis, dimensionality reduction visualization, and hierarchical clustering of features.</p> <p>The module is designed to help data scientists and analysts quickly understand their data through various visualization and statistical techniques before proceeding with model development.</p> <p>Functions:</p> <ul> <li> <code>na_percentages : Compute and visualize missing value percentages</code>             \u2013              </li> <li> <code>get_ecdf : Calculate empirical cumulative distribution function</code>             \u2013              </li> <li> <code>plot_ecdf : Plot ECDF with normal distribution comparison</code>             \u2013              </li> <li> <code>plot_pca_var_explained : Visualize PCA variance explanation</code>             \u2013              </li> <li> <code>plot_corr_matrix : Create correlation matrix heatmaps</code>             \u2013              </li> <li> <code>plot_featurebased_hier_clustering : Hierarchical clustering of features</code>             \u2013              </li> </ul> <p>Examples:</p> <p>Basic usage for data quality assessment:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from cmn_ai.tabular.eda import na_percentages, plot_corr_matrix\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create sample data with missing values\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'A': [1, 2, np.nan, 4, 5],\n...     'B': [1, np.nan, 3, 4, np.nan],\n...     'C': [1, 2, 3, 4, 5]\n... })\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check missing value percentages\n&gt;&gt;&gt; na_percentages(df, formatted=False)\nB    0.4\nA    0.2\ndtype: float64\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Plot correlation matrix\n&gt;&gt;&gt; plot_corr_matrix(df, method='pearson')\n</code></pre> <p>PCA variance analysis:</p> <pre><code>&gt;&gt;&gt; from sklearn.decomposition import PCA\n&gt;&gt;&gt; from cmn_ai.tabular.eda import plot_pca_var_explained\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Fit PCA on data\n&gt;&gt;&gt; pca = PCA().fit(df.dropna())\n&gt;&gt;&gt; plot_pca_var_explained(pca)\n</code></pre> Dependencies <ul> <li>numpy : For numerical operations and array handling</li> <li>pandas : For data manipulation and analysis</li> <li>matplotlib : For plotting and visualization</li> <li>seaborn : For enhanced statistical visualizations</li> <li>scipy : For statistical functions and clustering</li> <li>scikit-learn : For PCA and machine learning utilities</li> </ul> Notes <ul> <li>All plotting functions use matplotlib backend and will display plots   when called in interactive environments</li> <li>Correlation analysis supports Pearson, Kendall, and Spearman methods</li> <li>Hierarchical clustering uses Spearman correlation for feature similarity</li> <li>ECDF functions include comparison with theoretical normal distribution</li> </ul>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.get_ecdf","title":"<code>get_ecdf(a)</code>","text":"<p>Compute empirical cumulative distribution function (ECDF) of input array.</p> <p>The ECDF is a step function that jumps up by 1/n at each of the n data points. Its value at any specified value of the measured variable is the fraction of observations of the measured variable that are less than or equal to the specified value.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>list[float] | ndarray | Series</code>)           \u2013            <p>Input array to compute ECDF on. Can be a list, numpy array, or pandas Series.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[ndarray, ndarray]</code>           \u2013            <p>x : Sorted version of input array in ascending order y : Cumulative probability values (0 to 1) corresponding to each sorted value</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; x, y = get_ecdf([1, 3, 2, 4])\n&gt;&gt;&gt; print(x)\n[1 2 3 4]\n&gt;&gt;&gt; print(y)\n[0.25 0.5  0.75 1.  ]\n</code></pre>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.na_percentages","title":"<code>na_percentages(df, formatted=True)</code>","text":"<p>Compute percentage of missing values in dataframe columns.</p> <p>This function calculates the percentage of missing values (NaN) in each column of the input dataframe and returns either a raw pandas Series or a formatted/styled dataframe for better visualization.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>Input dataframe to compute missing values percentages.</p> </li> <li> <code>formatted</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, returns a styled dataframe with background gradient. If False, returns a raw pandas Series with percentages.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Series | DataFrame</code>           \u2013            <p>If formatted=True: Styled dataframe with feature names and NA percentages If formatted=False: Pandas Series with column names and NA percentages</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2, np.nan], 'B': [1, np.nan, 3], 'C': [1, 2, 3]})\n&gt;&gt;&gt; na_percentages(df, formatted=False)\nB    0.333333\nA    0.333333\ndtype: float64\n</code></pre>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.plot_corr_matrix","title":"<code>plot_corr_matrix(df, method='pearson', figsize=(12, 6))</code>","text":"<p>Plot correlation matrix heatmap with specified correlation method.</p> <p>Creates a heatmap visualization of the correlation matrix using the specified correlation method. The upper triangle is masked to avoid redundancy, and correlation values are displayed as annotations on the heatmap.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>Input dataframe to compute correlation matrix.</p> </li> <li> <code>method</code>               (<code>str</code>, default:                   <code>'pearson'</code> )           \u2013            <p>Correlation method to use. Options: 'pearson', 'kendall', 'spearman'.</p> </li> <li> <code>figsize</code>               (<code>tuple[int, int]</code>, default:                   <code>(12, 6)</code> )           \u2013            <p>Figure size as (width, height) in inches.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>Displays the correlation heatmap using matplotlib and seaborn.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; df = pd.DataFrame(np.random.randn(100, 5), columns=['A', 'B', 'C', 'D', 'E'])\n&gt;&gt;&gt; plot_corr_matrix(df, method='spearman')\n</code></pre>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.plot_ecdf","title":"<code>plot_ecdf(a, xlabel='X')</code>","text":"<p>Plot empirical cumulative distribution function (ECDF) with normal comparison.</p> <p>Creates a plot showing the empirical CDF of the input data alongside a theoretical normal CDF with the same mean and standard deviation for comparison purposes.</p> <p>Parameters:</p> <ul> <li> <code>a</code>               (<code>list[float] | ndarray | Series</code>)           \u2013            <p>Input array to compute and plot ECDF.</p> </li> <li> <code>xlabel</code>               (<code>str</code>, default:                   <code>\"X\"</code> )           \u2013            <p>Label for the x-axis of the plot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>Displays the plot using matplotlib.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = np.random.normal(0, 1, 1000)\n&gt;&gt;&gt; plot_ecdf(data, xlabel=\"Values\")\n</code></pre>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.plot_featurebased_hier_clustering","title":"<code>plot_featurebased_hier_clustering(X, feature_names=None, linkage_method='single', figsize=(16, 12))</code>","text":"<p>Plot feature-based hierarchical clustering dendrogram using Spearman correlation.</p> <p>Performs hierarchical clustering on features based on their Spearman correlation matrix and displays the resulting dendrogram. This helps identify groups of features that are highly correlated with each other.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray | DataFrame</code>)           \u2013            <p>Input data matrix or dataframe to compute hierarchical clustering.</p> </li> <li> <code>feature_names</code>               (<code>ndarray | list[str]</code>, default:                   <code>None</code> )           \u2013            <p>Names of features to use as labels in the dendrogram. If None, uses column names if X is a DataFrame, or generic labels if X is an array.</p> </li> <li> <code>linkage_method</code>               (<code>str</code>, default:                   <code>\"single\"</code> )           \u2013            <p>Linkage method for hierarchical clustering. Options: 'single', 'complete', 'average', 'weighted', 'centroid', 'median', 'ward'.</p> </li> <li> <code>figsize</code>               (<code>tuple[int, int]</code>, default:                   <code>(16, 12)</code> )           \u2013            <p>Figure size as (width, height) in inches.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>Displays the hierarchical clustering dendrogram using matplotlib.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; X = np.random.randn(100, 5)\n&gt;&gt;&gt; feature_names = ['Feature_A', 'Feature_B', 'Feature_C', 'Feature_D', 'Feature_E']\n&gt;&gt;&gt; plot_featurebased_hier_clustering(X, feature_names, linkage_method='ward')\n</code></pre>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.plot_pca_var_explained","title":"<code>plot_pca_var_explained(pca_transformer, figsize=(12, 6))</code>","text":"<p>Plot individual and cumulative variance explained by PCA components.</p> <p>Creates a bar plot showing the individual explained variance ratio for each principal component, along with a step plot showing the cumulative explained variance. This helps visualize how much information is captured by each component and how many components are needed to explain a certain percentage of the total variance.</p> <p>Parameters:</p> <ul> <li> <code>pca_transformer</code>               (<code>PCA</code>)           \u2013            <p>Fitted PCA transformer object from scikit-learn.</p> </li> <li> <code>figsize</code>               (<code>tuple[int, int]</code>, default:                   <code>(12, 6)</code> )           \u2013            <p>Figure size as (width, height) in inches.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>Displays the plot using matplotlib.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from sklearn.decomposition import PCA\n&gt;&gt;&gt; from sklearn.datasets import make_blobs\n&gt;&gt;&gt; X, _ = make_blobs(n_samples=100, n_features=10, random_state=42)\n&gt;&gt;&gt; pca = PCA().fit(X)\n&gt;&gt;&gt; plot_pca_var_explained(pca)\n</code></pre>"},{"location":"tabular/preprocessing/","title":"Preprocessing","text":"<p>Data preprocessing and transformation utilities for tabular data.</p> <p>This module provides transformers and preprocessing utilities that are compatible with scikit-learn Pipeline and ColumnTransformer. It includes specialized transformers for handling date/time features and other common preprocessing tasks in machine learning workflows.</p> <p>The transformers follow scikit-learn conventions with fit/transform methods and can be seamlessly integrated into preprocessing pipelines.</p> <p>Classes:</p> <ul> <li> <code>DateTransformer : Transform date features into derived attributes</code>           \u2013            </li> </ul> <p>Examples:</p> <p>Basic usage with date features:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from cmn_ai.tabular.preprocessing import DateTransformer\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create sample data with date column\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'date': pd.to_datetime(['2023-01-01', '2023-02-15', '2023-03-30']),\n...     'value': [1, 2, 3]\n... })\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Transform date features\n&gt;&gt;&gt; transformer = DateTransformer(time=True, drop=True)\n&gt;&gt;&gt; df_transformed = transformer.fit_transform(df)\n&gt;&gt;&gt; print(df_transformed.columns)\nIndex(['value', 'date_Year', 'date_Month', 'date_Week', 'date_Day',\n       'date_Dayofweek', 'date_Dayofyear', 'date_Is_month_end',\n       'date_Is_month_start', 'date_Is_quarter_end', 'date_Is_quarter_start',\n       'date_Is_year_end', 'date_Is_year_start', 'date_Hour', 'date_Minute',\n       'date_Second', 'date_na_indicator'], dtype='object')\n</code></pre> <p>Integration with scikit-learn Pipeline:</p> <pre><code>&gt;&gt;&gt; from sklearn.pipeline import Pipeline\n&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler\n&gt;&gt;&gt;\n&gt;&gt;&gt; pipeline = Pipeline([\n...     ('date_transform', DateTransformer()),\n...     ('scaler', StandardScaler())\n... ])\n&gt;&gt;&gt; pipeline.fit_transform(df)\n</code></pre> Dependencies <ul> <li>numpy : For numerical operations and array handling</li> <li>pandas : For data manipulation and analysis</li> <li>scikit-learn : For base transformer classes and pipeline compatibility</li> </ul> Notes <ul> <li>All transformers are compatible with scikit-learn Pipeline and ColumnTransformer</li> <li>DateTransformer automatically detects datetime64 columns if date_feats is None</li> <li>Missing value indicators are automatically added for date features</li> <li>Time-related features (Hour, Minute, Second) are optional and disabled by default</li> </ul>"},{"location":"tabular/preprocessing/#cmn_ai.tabular.preprocessing.DateTransformer","title":"<code>DateTransformer</code>","text":"<p>               Bases: <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Transform date features by deriving useful date/time attributes.</p> <p>This transformer extracts various temporal features from datetime columns, including date attributes (year, month, day, etc.) and optional time attributes (hour, minute, second). It also adds missing value indicators for each date feature.</p> <p>The transformer is compatible with scikit-learn Pipeline and can be used in preprocessing workflows. It automatically detects datetime64 columns if no specific date features are provided.</p> <p>Attributes:</p> <ul> <li> <code>date_feats</code>               (<code>Iterable[str] | None, default=None</code>)           \u2013            <p>list of date feature column names to transform.</p> </li> <li> <code>time</code>               (<code>bool</code>)           \u2013            <p>Whether to include time-related features (Hour, Minute, Second).</p> </li> <li> <code>drop</code>               (<code>bool</code>)           \u2013            <p>Whether to drop original date features after transformation.</p> </li> <li> <code>attrs</code>               (<code>list[str]</code>)           \u2013            <p>list of date attributes to extract from each date feature.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from cmn_ai.tabular.preprocessing import DateTransformer\n&gt;&gt;&gt;\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'date': pd.to_datetime(['2023-01-01', '2023-02-15']),\n...     'value': [1, 2]\n... })\n&gt;&gt;&gt;\n&gt;&gt;&gt; transformer = DateTransformer(time=True)\n&gt;&gt;&gt; df_transformed = transformer.fit_transform(df)\n&gt;&gt;&gt; print(df_transformed.columns.tolist())\n['value', 'date_Year', 'date_Month', 'date_Week', 'date_Day',\n 'date_Dayofweek', 'date_Dayofyear', 'date_Is_month_end',\n 'date_Is_month_start', 'date_Is_quarter_end', 'date_Is_quarter_start',\n 'date_Is_year_end', 'date_Is_year_start', 'date_Hour', 'date_Minute',\n 'date_Second', 'date_na_indicator']\n</code></pre>"},{"location":"tabular/preprocessing/#cmn_ai.tabular.preprocessing.DateTransformer.__init__","title":"<code>__init__(date_feats=None, time=False, drop=True)</code>","text":"<p>Initialize DateTransformer.</p> <p>Parameters:</p> <ul> <li> <code>date_feats</code>               (<code>Iterable[str]</code>, default:                   <code>None</code> )           \u2013            <p>Date features to transform. If None, all features with <code>datetime64</code> data type will be automatically detected and used.</p> </li> <li> <code>time</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to add time-related derived features such as Hour, Minute, Second. If True, adds Hour, Minute, and Second attributes to the transformation.</p> </li> <li> <code>drop</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to drop original date features after transformation. If True, original date columns are removed from the output. If False, original date columns are preserved alongside derived features.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; transformer = DateTransformer(\n...     date_feats=['date_col'],\n...     time=True,\n...     drop=False\n... )\n</code></pre>"},{"location":"tabular/preprocessing/#cmn_ai.tabular.preprocessing.DateTransformer.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Fit the transformer by identifying date features.</p> <p>This method populates the date_feats attribute if not provided at initialization. It scans the input dataframe for columns with datetime64 data type and stores them for transformation.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>Input dataframe containing the date features to transform. Must contain at least one datetime64 column if date_feats is None.</p> </li> <li> <code>y</code>               (<code>ndarray | DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>Target values. Included for compatibility with scikit-learn transformers and pipelines but not used in this transformer.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>DateTransformer</code> )          \u2013            <p>Fitted transformer instance with populated date_feats attribute.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'date': pd.to_datetime(['2023-01-01', '2023-02-15']),\n...     'value': [1, 2]\n... })\n&gt;&gt;&gt; transformer = DateTransformer()\n&gt;&gt;&gt; fitted_transformer = transformer.fit(df)\n&gt;&gt;&gt; print(fitted_transformer.date_feats)\n['date']\n</code></pre>"},{"location":"tabular/preprocessing/#cmn_ai.tabular.preprocessing.DateTransformer.transform","title":"<code>transform(X, y=None)</code>","text":"<p>Transform date features by extracting derived attributes.</p> <p>For each date feature, this method creates new columns with extracted date/time attributes. It also adds missing value indicators for each date feature. The transformation preserves all non-date columns.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>Input dataframe containing the date features to transform. Must contain the same date features used during fitting.</p> </li> <li> <code>y</code>               (<code>ndarray | DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>Target values. Included for compatibility with scikit-learn transformers and pipelines but not used in this transformer.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>Transformed dataframe with derived date/time features. Contains original non-date columns plus new derived columns. Original date columns are dropped if drop=True.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'date': pd.to_datetime(['2023-01-01', '2023-02-15']),\n...     'value': [1, 2]\n... })\n&gt;&gt;&gt; transformer = DateTransformer(time=True)\n&gt;&gt;&gt; transformer.fit(df)\n&gt;&gt;&gt; df_transformed = transformer.transform(df)\n&gt;&gt;&gt; print(df_transformed['date_Year'].tolist())\n[2023, 2023]\n&gt;&gt;&gt; print(df_transformed['date_Month'].tolist())\n[1, 2]\n</code></pre>"},{"location":"text/data/","title":"Data","text":"<p>Text data utilities for text processing and dataset management.</p> <p>This module provides utilities for working with text data in machine learning pipelines. It includes classes and functions for loading, managing, and processing text datasets with support for various text file formats and transformations.</p> <p>The module is designed to work seamlessly with text files and integrates with the broader cmn_ai data processing pipeline.</p> <p>Functions:</p> <ul> <li> <code>None</code>             \u2013              </li> </ul> <p>Classes:</p> <ul> <li> <code>TextList : Text dataset container for managing collections of text files</code>           \u2013            </li> </ul> Notes <p>This module extends the base data utilities to provide text-specific functionality for natural language processing workflows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.text.data import TextList\n&gt;&gt;&gt; # Create text dataset from directory\n&gt;&gt;&gt; texts = TextList.from_files('./data/texts')\n&gt;&gt;&gt; # Access first text file\n&gt;&gt;&gt; text = texts[0]  # Returns string content\n&gt;&gt;&gt; print(len(text))  # Number of characters\n</code></pre>"},{"location":"text/data/#cmn_ai.text.data.TextList","title":"<code>TextList</code>","text":"<p>               Bases: <code>ItemList</code></p> <p>Text dataset container for managing collections of text files.</p> <p>A specialized ItemList subclass for handling text datasets. It provides functionality to load and manage collections of text files with support for various text formats, transformations, and file discovery.</p> <p>Attributes:</p> <ul> <li> <code>path</code>               (<code>Path</code>)           \u2013            <p>Base path where the text files are located.</p> </li> <li> <code>tfms</code>               (<code>(callable, optional)</code>)           \u2013            <p>Transformations to apply to text when retrieved.</p> </li> <li> <code>data</code>               (<code>list[Path]</code>)           \u2013            <p>List of text file paths.</p> </li> <li> <code>encoding</code>               (<code>str</code>)           \u2013            <p>Character encoding used to read text files.</p> </li> </ul> Notes <p>This class extends ItemList to provide text-specific functionality. Text files are loaded and decoded when accessed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create TextList from a directory\n&gt;&gt;&gt; text_list = TextList.from_files('./data/texts')\n&gt;&gt;&gt; # Access first text file\n&gt;&gt;&gt; text = text_list[0]  # Returns string content\n&gt;&gt;&gt; # Create with specific encoding\n&gt;&gt;&gt; text_list = TextList.from_files('./data', encoding='latin-1')\n&gt;&gt;&gt; # Create with transformations\n&gt;&gt;&gt; def preprocess(text): return text.lower().strip()\n&gt;&gt;&gt; text_list = TextList.from_files('./data', tfms=preprocess)\n</code></pre>"},{"location":"text/data/#cmn_ai.text.data.TextList.__init__","title":"<code>__init__(items, path='.', tfms=None, encoding='utf8')</code>","text":"<p>Initialize TextList with text files and configuration.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>Iterable</code>)           \u2013            <p>Items to create list from (typically file paths).</p> </li> <li> <code>path</code>               (<code>str or Path</code>, default:                   <code>\".\"</code> )           \u2013            <p>Path of the items that were used to create the list.</p> </li> <li> <code>tfms</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>Transformations to apply on text before returning them.</p> </li> <li> <code>encoding</code>               (<code>str</code>, default:                   <code>\"utf8\"</code> )           \u2013            <p>Character encoding used to read text files.</p> </li> </ul>"},{"location":"text/data/#cmn_ai.text.data.TextList.from_files","title":"<code>from_files(path, extensions='.txt', include=None, recurse=True, tfms=None, encoding='utf8')</code>  <code>classmethod</code>","text":"<p>Create a TextList from files in a directory.</p> <p>Factory method to create a TextList by discovering text files in the specified directory. Supports various text formats and recursive directory traversal.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str or Path</code>)           \u2013            <p>Path for the root directory to search for text files.</p> </li> <li> <code>extensions</code>               (<code>str or iterable of str</code>, default:                   <code>\".txt\"</code> )           \u2013            <p>File extensions to include. Defaults to .txt files.</p> </li> <li> <code>include</code>               (<code>iterable of str</code>, default:                   <code>None</code> )           \u2013            <p>Top-level directory(ies) under <code>path</code> to use for searching files. If None, searches all directories.</p> </li> <li> <code>recurse</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to search subdirectories recursively.</p> </li> <li> <code>tfms</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>Transformations to apply to text before returning them.</p> </li> <li> <code>encoding</code>               (<code>str</code>, default:                   <code>\"utf8\"</code> )           \u2013            <p>Character encoding used to read text files.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TextList</code>           \u2013            <p>New TextList instance containing discovered text files.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create from directory with default settings\n&gt;&gt;&gt; texts = TextList.from_files('./data/texts')\n&gt;&gt;&gt; # Create with specific extensions\n&gt;&gt;&gt; texts = TextList.from_files('./data', extensions=['.txt', '.md'])\n&gt;&gt;&gt; # Create with custom encoding\n&gt;&gt;&gt; texts = TextList.from_files('./data', encoding='latin-1')\n&gt;&gt;&gt; # Create without recursion\n&gt;&gt;&gt; texts = TextList.from_files('./data', recurse=False)\n</code></pre>"},{"location":"text/data/#cmn_ai.text.data.TextList.get","title":"<code>get(item)</code>","text":"<p>Load and return text content from file path.</p> <p>Reads a text file using the specified encoding and returns the text content as a string. This method is called automatically when accessing items from the TextList.</p> <p>Parameters:</p> <ul> <li> <code>item</code>               (<code>Path or str</code>)           \u2013            <p>File path to the text file to load, or string content.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Text content from the file.</p> </li> </ul> Notes <p>If the item is already a string, it is returned as-is. If it's a file path, the file is read using the specified encoding. If transformations are specified in the TextList, they will be applied after loading.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; text_list = TextList.from_files('./data')\n&gt;&gt;&gt; text = text_list.get(Path('./data/document.txt'))\n&gt;&gt;&gt; print(len(text))  # Number of characters\n&gt;&gt;&gt; # Direct string access\n&gt;&gt;&gt; text = text_list.get(\"Hello, world!\")\n&gt;&gt;&gt; print(text)  # \"Hello, world!\"\n</code></pre>"},{"location":"utils/data/","title":"Data","text":"<p>Data utilities for PyTorch-based machine learning workflows.</p> <p>This module provides utilities for working with data in PyTorch-based machine learning pipelines. It includes functions and classes for creating and managing DataLoaders, device management for tensors and collections, data collation and preprocessing, file system operations for data discovery, dataset splitting and labeling strategies, and container classes for organizing data items.</p> <p>The module is designed to work seamlessly with PyTorch's Dataset and DataLoader classes, as well as Hugging Face datasets.</p> <p>Functions:</p> <ul> <li> <code>get_dls : Create training and validation DataLoaders</code>             \u2013              </li> <li> <code>to_device : Copy tensor</code>             \u2013              </li> <li> <code>to_cpu : Copy tensor</code>             \u2013              </li> <li> <code>collate_dict : Create collate function for Hugging Face Dataset dictionary</code>             \u2013              </li> <li> <code>collate_device : Create collate function that moves batch to specified device</code>             \u2013              </li> <li> <code>compose : Apply transformations in sequence to input</code>             \u2013              </li> <li> <code>get_files : Get filenames in path with specified extensions</code>             \u2013              </li> <li> <code>random_splitter : Randomly split items with specified probability</code>             \u2013              </li> <li> <code>grandparent_splitter : Split items based on directory structure</code>             \u2013              </li> <li> <code>split_by_func : Split items into train/valid lists using a function</code>             \u2013              </li> <li> <code>parent_labeler : Label a file based on its parent directory</code>             \u2013              </li> <li> <code>label_by_func : Label split data using a labeling function</code>             \u2013              </li> </ul> <p>Classes:</p> <ul> <li> <code>DataLoaders : Container for training and validation DataLoaders</code>           \u2013            </li> <li> <code>ListContainer : Extended list with improved representation</code>           \u2013            </li> <li> <code>ItemList : Base class for all types of datasets</code>           \u2013            </li> <li> <code>SplitData : Split ItemList into train and validation data lists</code>           \u2013            </li> <li> <code>LabeledData : Create labeled data with input and target ItemLists</code>           \u2013            </li> </ul> Notes <p>This module is part of the cmn_ai library and provides high-level abstractions for common data processing tasks in machine learning workflows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.utils.data import get_files, to_device, compose, SplitData, LabeledData\n&gt;&gt;&gt; from cmn_ai.utils.data import ItemList, grandparent_splitter, parent_labeler\n&gt;&gt;&gt; # File operations\n&gt;&gt;&gt; files = get_files('./data', extensions=['.txt', '.csv'])\n&gt;&gt;&gt; # Device operations\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; tensor = torch.randn(3, 3)\n&gt;&gt;&gt; tensor_on_gpu = to_device(tensor, 'cuda')\n&gt;&gt;&gt; # Function composition\n&gt;&gt;&gt; def add_one(x): return x + 1\n&gt;&gt;&gt; def multiply_two(x): return x * 2\n&gt;&gt;&gt; result = compose(5, [add_one, multiply_two])  # Returns 12\n&gt;&gt;&gt; # Data splitting\n&gt;&gt;&gt; items = ItemList(['train/cat/1.jpg', 'valid/dog/2.jpg', 'train/cat/3.jpg'])\n&gt;&gt;&gt; split_data = SplitData.split_by_func(items, grandparent_splitter)\n&gt;&gt;&gt; print(f\"Train: {len(split_data.train)}, Valid: {len(split_data.valid)}\")\n&gt;&gt;&gt; # Labeled data\n&gt;&gt;&gt; x_items = ItemList(['image1.jpg', 'image2.jpg'])\n&gt;&gt;&gt; y_items = ItemList(['cat', 'dog'])\n&gt;&gt;&gt; labeled_data = LabeledData(x_items, y_items)\n&gt;&gt;&gt; x, y = labeled_data[0]  # Returns ('image1.jpg', 'cat')\n&gt;&gt;&gt; # Labeling with function\n&gt;&gt;&gt; items = ItemList(['data/cat/1.jpg', 'data/dog/2.jpg'])\n&gt;&gt;&gt; labeled = LabeledData.label_by_func(items, parent_labeler)\n&gt;&gt;&gt; print(labeled.y[0], labeled.y[1])  # 'cat' 'dog'\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.DataLoaders","title":"<code>DataLoaders</code>","text":"<p>Container for training and validation DataLoaders.</p> <p>A convenience class that holds training and validation DataLoaders and provides easy access to them.</p> <p>Attributes:</p> <ul> <li> <code>train</code>               (<code>DataLoader</code>)           \u2013            <p>Training DataLoader.</p> </li> <li> <code>valid</code>               (<code>DataLoader</code>)           \u2013            <p>Validation DataLoader.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; train_dl = DataLoader(train_ds, batch_size=32)\n&gt;&gt;&gt; valid_dl = DataLoader(valid_ds, batch_size=32)\n&gt;&gt;&gt; dls = DataLoaders(train_dl, valid_dl)\n&gt;&gt;&gt; dls.train  # Access training DataLoader\n&gt;&gt;&gt; dls.valid  # Access validation DataLoader\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.DataLoaders.__init__","title":"<code>__init__(*dls)</code>","text":"<p>Initialize DataLoaders with training and validation DataLoaders.</p> <p>Parameters:</p> <ul> <li> <code>*dls</code>               (<code>DataLoader</code>, default:                   <code>()</code> )           \u2013            <p>List of DataLoaders. First is assumed to be training, second is assumed to be validation.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.DataLoaders.from_dd","title":"<code>from_dd(dd, batch_size=32, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create DataLoaders from Hugging Face Dataset dictionary.</p> <p>Parameters:</p> <ul> <li> <code>dd</code>               (<code>DatasetDict</code>)           \u2013            <p>Hugging Face Dataset dictionary. Must have at least two datasets: train and valid/test datasets.</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>32</code> )           \u2013            <p>Batch size passed to DataLoader.</p> </li> <li> <code>**kwargs</code>               (<code>dict</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to DataLoader.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataLoaders</code>           \u2013            <p>DataLoaders instance with train and validation DataLoaders.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datasets import DatasetDict\n&gt;&gt;&gt; dd = DatasetDict({'train': train_ds, 'validation': valid_ds})\n&gt;&gt;&gt; dls = DataLoaders.from_dd(dd, batch_size=32)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList","title":"<code>ItemList</code>","text":"<p>               Bases: <code>ListContainer</code></p> <p>Base class for all types of datasets such as image, text, etc.</p> <p>A container class that holds items and provides functionality for applying transformations and retrieving items with transformations applied.</p> <p>Attributes:</p> <ul> <li> <code>path</code>               (<code>Path</code>)           \u2013            <p>Path of the items that were used to create the list.</p> </li> <li> <code>tfms</code>               (<code>(callable, optional)</code>)           \u2013            <p>Transformations to apply on items before returning them.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; items = ItemList(['file1.jpg', 'file2.jpg'], path='./data')\n&gt;&gt;&gt; items[0]  # Returns transformed item\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Get item(s) with transformations applied.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>               (<code>int or slice</code>)           \u2013            <p>Index or slice to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any or list of Any</code>           \u2013            <p>Item(s) with transformations applied.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList.__init__","title":"<code>__init__(items, path='.', tfms=None, **kwargs)</code>","text":"<p>Initialize ItemList with items, path, and transformations.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>Sequence</code>)           \u2013            <p>Items to create list.</p> </li> <li> <code>path</code>               (<code>str or Path</code>, default:                   <code>\".\"</code> )           \u2013            <p>Path of the items that were used to create the list.</p> </li> <li> <code>tfms</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>Transformations to apply on items before returning them.</p> </li> <li> <code>**kwargs</code>               (<code>dict</code>, default:                   <code>{}</code> )           \u2013            <p>Additional attributes to set on the instance.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList.get","title":"<code>get(item)</code>","text":"<p>Get item without transformations.</p> <p>Every class that inherits from <code>ItemList</code> has to override this method to provide custom item retrieval logic.</p> <p>Parameters:</p> <ul> <li> <code>item</code>               (<code>Any</code>)           \u2013            <p>Item to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>           \u2013            <p>Retrieved item.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList.new","title":"<code>new(items, cls=None)</code>","text":"<p>Create a new instance of the ItemList with items.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>Sequence</code>)           \u2013            <p>The items to create the list from.</p> </li> <li> <code>cls</code>               (<code>ItemList</code>, default:                   <code>None</code> )           \u2013            <p>The class to instantiate. If None, the same class will be used.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ItemList</code>           \u2013            <p>The new instance of the ItemList.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData","title":"<code>LabeledData</code>","text":"<p>Create labeled data with input and target ItemLists.</p> <p>A container class that holds input (x) and target (y) ItemLists and provides functionality for processing and retrieving labeled data.</p> <p>Attributes:</p> <ul> <li> <code>x</code>               (<code>ItemList</code>)           \u2013            <p>Input items to the model.</p> </li> <li> <code>y</code>               (<code>ItemList</code>)           \u2013            <p>Label items.</p> </li> <li> <code>proc_x</code>               (<code>Processor or iterable of Processor, optional</code>)           \u2013            <p>Input items processor(s).</p> </li> <li> <code>proc_y</code>               (<code>Processor or iterable of Processor, optional</code>)           \u2013            <p>Label items processor(s).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x_items = ItemList(['image1.jpg', 'image2.jpg'])\n&gt;&gt;&gt; y_items = ItemList(['cat', 'dog'])\n&gt;&gt;&gt; labeled_data = LabeledData(x_items, y_items)\n&gt;&gt;&gt; x, y = labeled_data[0]  # Get first labeled example\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Get labeled example(s) at index.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>               (<code>int or slice</code>)           \u2013            <p>Index or slice to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple or list of tuple</code>           \u2013            <p>Labeled example(s) as (x, y) pairs.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.__init__","title":"<code>__init__(x, y, proc_x=None, proc_y=None)</code>","text":"<p>Initialize LabeledData with input and target ItemLists.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>ItemList</code>)           \u2013            <p>Input items to the model.</p> </li> <li> <code>y</code>               (<code>ItemList</code>)           \u2013            <p>Label items.</p> </li> <li> <code>proc_x</code>               (<code>Processor or iterable of Processor</code>, default:                   <code>None</code> )           \u2013            <p>Input items processor(s).</p> </li> <li> <code>proc_y</code>               (<code>Processor or iterable of Processor</code>, default:                   <code>None</code> )           \u2013            <p>Label items processor(s).</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of labeled examples.</p>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.label_by_func","title":"<code>label_by_func(item_list, label_func, proc_x=None, proc_y=None)</code>  <code>classmethod</code>","text":"<p>Label an ItemList using a labeling function.</p> <p>Parameters:</p> <ul> <li> <code>item_list</code>               (<code>ItemList</code>)           \u2013            <p>The ItemList to be labeled.</p> </li> <li> <code>label_func</code>               (<code>callable</code>)           \u2013            <p>The function to be used for labeling.</p> </li> <li> <code>proc_x</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>The processor to be applied to the input data.</p> </li> <li> <code>proc_y</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>The processor to be applied to the label data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>LabeledData</code>           \u2013            <p>The labeled ItemList.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; items = ItemList(['image1.jpg', 'image2.jpg'])\n&gt;&gt;&gt; labeled = LabeledData.label_by_func(items, parent_labeler)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.process","title":"<code>process(item_list, proc)</code>","text":"<p>Apply processors to an ItemList.</p> <p>Parameters:</p> <ul> <li> <code>item_list</code>               (<code>ItemList</code>)           \u2013            <p>The ItemList to process.</p> </li> <li> <code>proc</code>               (<code>Processor or iterable of Processor</code>)           \u2013            <p>The processor or list of processors to apply.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ItemList</code>           \u2013            <p>The processed ItemList.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.x_obj","title":"<code>x_obj(idx)</code>","text":"<p>Get input object at index after deprocessing.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>               (<code>int</code>)           \u2013            <p>Index of the input object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>           \u2013            <p>The input object at index idx after applying all processors in proc_x.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.y_obj","title":"<code>y_obj(idx)</code>","text":"<p>Get label object at index after deprocessing.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>               (<code>int</code>)           \u2013            <p>Index of the label object to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>           \u2013            <p>The label object at index idx after applying all processors in proc_y.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.ListContainer","title":"<code>ListContainer</code>","text":"<p>               Bases: <code>UserList</code></p> <p>Extended list with improved representation.</p> <p>Extends builtin list by changing the creation of the list from the given items and changing repr to return first 10 items along with total number of items and the class name. This will be the base class where other containers will inherit from.</p> <p>Attributes:</p> <ul> <li> <code>data</code>               (<code>list</code>)           \u2013            <p>The underlying list data.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; container = ListContainer([1, 2, 3, 4, 5])\n&gt;&gt;&gt; print(container)\nListContainer: (5 items)\n[1, 2, 3, 4, 5]\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.ListContainer.__init__","title":"<code>__init__(items)</code>","text":"<p>Initialize ListContainer with items.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>Any</code>)           \u2013            <p>Items to create list from.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.SplitData","title":"<code>SplitData</code>","text":"<p>Split ItemList into train and validation data lists.</p> <p>A container class that holds training and validation ItemLists and provides functionality for creating DataLoaders from them.</p> <p>Attributes:</p> <ul> <li> <code>train</code>               (<code>ItemList</code>)           \u2013            <p>Training items.</p> </li> <li> <code>valid</code>               (<code>ItemList</code>)           \u2013            <p>Validation items.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; train_items = ItemList(['train1.jpg', 'train2.jpg'])\n&gt;&gt;&gt; valid_items = ItemList(['valid1.jpg', 'valid2.jpg'])\n&gt;&gt;&gt; split_data = SplitData(train_items, valid_items)\n&gt;&gt;&gt; train_dl, valid_dl = split_data.to_dls(batch_size=32)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.SplitData.__getattr__","title":"<code>__getattr__(k)</code>","text":"<p>Delegate attribute access to training ItemList.</p>"},{"location":"utils/data/#cmn_ai.utils.data.SplitData.__init__","title":"<code>__init__(train, valid)</code>","text":"<p>Initialize SplitData with training and validation ItemLists.</p> <p>Parameters:</p> <ul> <li> <code>train</code>               (<code>ItemList</code>)           \u2013            <p>Training items.</p> </li> <li> <code>valid</code>               (<code>ItemList</code>)           \u2013            <p>Validation items.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.SplitData.__setstate__","title":"<code>__setstate__(data)</code>","text":"<p>Set state for pickling.</p>"},{"location":"utils/data/#cmn_ai.utils.data.SplitData.split_by_func","title":"<code>split_by_func(item_list, split_func)</code>  <code>classmethod</code>","text":"<p>Split ItemList by splitter function.</p> <p>Parameters:</p> <ul> <li> <code>item_list</code>               (<code>ItemList</code>)           \u2013            <p>ItemList to split.</p> </li> <li> <code>split_func</code>               (<code>callable</code>)           \u2013            <p>Function to use for splitting items.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SplitData</code>           \u2013            <p>SplitData object with train and validation ItemLists.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; items = ItemList(['train/cat/1.jpg', 'val/dog/2.jpg'])\n&gt;&gt;&gt; split_data = SplitData.split_by_func(items, grandparent_splitter)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.SplitData.to_dls","title":"<code>to_dls(batch_size=32, **kwargs)</code>","text":"<p>Create training and validation DataLoaders.</p> <p>Parameters:</p> <ul> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>32</code> )           \u2013            <p>Batch size for DataLoaders.</p> </li> <li> <code>**kwargs</code>               (<code>dict</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to DataLoader.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[DataLoader, DataLoader]</code>           \u2013            <p>Training and validation DataLoaders.</p> </li> </ul>"},{"location":"utils/data/#cmn_ai.utils.data.collate_device","title":"<code>collate_device(device)</code>","text":"<p>Create a collate function that moves batch to specified device.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str or device</code>)           \u2013            <p>Device to copy batch to.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>           \u2013            <p>Collate function that returns batch on specified device.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; collate_fn = collate_device('cuda')\n&gt;&gt;&gt; dataloader = DataLoader(dataset, collate_fn=collate_fn)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.collate_dict","title":"<code>collate_dict(*keys)</code>","text":"<p>Create a collate function for a Dataset dictionary.</p> <p>Creates a collate function that extracts specified keys from a batch and applies PyTorch's default collate function.</p> <p>Parameters:</p> <ul> <li> <code>*keys</code>               (<code>str</code>, default:                   <code>()</code> )           \u2013            <p>Keys to extract from the batch dictionary.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>callable</code>           \u2013            <p>Collate function that returns tuple of collated inputs.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; collate_fn = collate_dict('input_ids', 'attention_mask', 'labels')\n&gt;&gt;&gt; dataloader = DataLoader(dataset, collate_fn=collate_fn)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.compose","title":"<code>compose(x, funcs, *args, order='order', **kwargs)</code>","text":"<p>Apply transformations in sequence to input.</p> <p>Applies transformations in <code>funcs</code> to the input <code>x</code> in the specified order. Functions are sorted by their <code>order</code> attribute if present.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Any</code>)           \u2013            <p>Input to transform.</p> </li> <li> <code>funcs</code>               (<code>callable or iterable of callables</code>)           \u2013            <p>Function(s) to apply to input.</p> </li> <li> <code>*args</code>               (<code>tuple</code>, default:                   <code>()</code> )           \u2013            <p>Positional arguments passed to each function.</p> </li> <li> <code>order</code>               (<code>str</code>, default:                   <code>'order'</code> )           \u2013            <p>Attribute name used to determine function order.</p> </li> <li> <code>**kwargs</code>               (<code>dict</code>, default:                   <code>{}</code> )           \u2013            <p>Keyword arguments passed to each function.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>           \u2013            <p>Transformed input.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def add_one(x): return x + 1\n&gt;&gt;&gt; def multiply_two(x): return x * 2\n&gt;&gt;&gt; result = compose(5, [add_one, multiply_two])  # Returns 12\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.get_dls","title":"<code>get_dls(train_ds, valid_ds, batch_size, **kwargs)</code>","text":"<p>Create training and validation DataLoaders.</p> <p>Creates two DataLoaders: one for training and one for validation. The validation DataLoader has twice the batch size and doesn't shuffle data.</p> <p>Parameters:</p> <ul> <li> <code>train_ds</code>               (<code>Dataset</code>)           \u2013            <p>Training dataset.</p> </li> <li> <code>valid_ds</code>               (<code>Dataset</code>)           \u2013            <p>Validation dataset.</p> </li> <li> <code>batch_size</code>               (<code>int</code>)           \u2013            <p>Batch size for the training DataLoader. Validation DataLoader will use batch_size * 2.</p> </li> <li> <code>**kwargs</code>               (<code>dict</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to DataLoader constructor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[DataLoader, DataLoader]</code>           \u2013            <p>A tuple containing (train_dataloader, valid_dataloader).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; train_ds = MyDataset(train_data)\n&gt;&gt;&gt; valid_ds = MyDataset(valid_data)\n&gt;&gt;&gt; train_dl, valid_dl = get_dls(train_ds, valid_ds, batch_size=32)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.get_files","title":"<code>get_files(path, extensions=None, include=None, recurse=False)</code>","text":"<p>Get filenames in path with specified extensions.</p> <p>Get filenames in <code>path</code> that have extension <code>extensions</code> starting with <code>path</code> and optionally recurse to subdirectories.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str or Path</code>)           \u2013            <p>Path for the root directory to search for files.</p> </li> <li> <code>extensions</code>               (<code>str or iterable of str</code>, default:                   <code>None</code> )           \u2013            <p>Suffixes of filenames to look for (with or without dot).</p> </li> <li> <code>include</code>               (<code>iterable of str</code>, default:                   <code>None</code> )           \u2013            <p>Top-level directory(ies) under <code>path</code> to use for searching files.</p> </li> <li> <code>recurse</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to search subdirectories recursively.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list of Path</code>           \u2013            <p>List of file paths that end with specified extensions under <code>path</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; files = get_files('./data', extensions=['.jpg', '.png'])\n&gt;&gt;&gt; files = get_files('./data', extensions='.txt', recurse=True)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.grandparent_splitter","title":"<code>grandparent_splitter(f_name, valid_name='valid', train_name='train')</code>","text":"<p>Split items based on directory structure.</p> <p>Split items based on whether they fall under validation or training directories. This assumes that the directory structure is train/label/items or valid/label/items.</p> <p>Parameters:</p> <ul> <li> <code>f_name</code>               (<code>str or Path</code>)           \u2013            <p>Item's filename.</p> </li> <li> <code>valid_name</code>               (<code>str</code>, default:                   <code>\"valid\"</code> )           \u2013            <p>Name of the directory that holds the validation items.</p> </li> <li> <code>train_name</code>               (<code>str</code>, default:                   <code>\"train\"</code> )           \u2013            <p>Name of the directory that holds the training items.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool or None</code>           \u2013            <p>True if the item is in validation, False if in training, None if neither.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; splitter = lambda f: grandparent_splitter(f, 'val', 'train')\n&gt;&gt;&gt; is_valid = splitter('train/cat/image.jpg')  # Returns False\n&gt;&gt;&gt; is_valid = splitter('val/dog/image.jpg')    # Returns True\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.label_by_func","title":"<code>label_by_func(splitted_data, label_func, proc_x=None, proc_y=None)</code>","text":"<p>Label split data using a labeling function.</p> <p>Parameters:</p> <ul> <li> <code>splitted_data</code>               (<code>SplitData</code>)           \u2013            <p>The split data to be labeled.</p> </li> <li> <code>label_func</code>               (<code>callable</code>)           \u2013            <p>The function to be used for labeling.</p> </li> <li> <code>proc_x</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>The processor to be applied to the input data.</p> </li> <li> <code>proc_y</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>The processor to be applied to the label data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SplitData</code>           \u2013            <p>The labeled split data.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_data = SplitData(train_items, valid_items)\n&gt;&gt;&gt; labeled_split = label_by_func(split_data, parent_labeler)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.parent_labeler","title":"<code>parent_labeler(f_name)</code>","text":"<p>Label a file based on its parent directory.</p> <p>Parameters:</p> <ul> <li> <code>f_name</code>               (<code>str or Path</code>)           \u2013            <p>Filename to get the parent directory.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Name of the parent directory.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; label = parent_labeler('data/cat/image.jpg')  # Returns 'cat'\n&gt;&gt;&gt; label = parent_labeler('data/dog/image.png')  # Returns 'dog'\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.random_splitter","title":"<code>random_splitter(f_name, p_valid=0.2)</code>","text":"<p>Randomly split items with specified probability.</p> <p>Randomly split items with <code>p_valid</code> probability to be in the validation set.</p> <p>Parameters:</p> <ul> <li> <code>f_name</code>               (<code>str</code>)           \u2013            <p>Item's filename. Not used here, but left for API consistency with other splitters.</p> </li> <li> <code>p_valid</code>               (<code>float</code>, default:                   <code>0.2</code> )           \u2013            <p>Probability of the item to be in the validation set.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>True if the item is in validation else False (training).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; splitter = lambda f: random_splitter(f, p_valid=0.3)\n&gt;&gt;&gt; is_valid = splitter('file.jpg')  # Returns True or False\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.split_by_func","title":"<code>split_by_func(items, func)</code>","text":"<p>Split items into train/valid lists using a function.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>Iterable</code>)           \u2013            <p>Items to be split into train/valid.</p> </li> <li> <code>func</code>               (<code>callable</code>)           \u2013            <p>Split function to split items. Should return True for validation items, False for training items, and None to exclude items.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[list, list]</code>           \u2013            <p>Train and valid item lists.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; files = ['train/cat/1.jpg', 'val/dog/2.jpg', 'train/cat/3.jpg']\n&gt;&gt;&gt; train, valid = split_by_func(files, grandparent_splitter)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.to_cpu","title":"<code>to_cpu(x)</code>","text":"<p>Copy tensor(s) to CPU.</p> <p>If a tensor is already on the CPU, returns the tensor itself; otherwise, returns a copy of the tensor on CPU.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor or Iterable[Tensor] or Mapping[str, Tensor]</code>)           \u2013            <p>Tensor or collection of tensors to move to CPU.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor or Iterable[Tensor] or Mapping[str, Tensor]</code>           \u2013            <p>Copied tensor(s) on CPU.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tensor = torch.randn(3, 3, device='cuda')\n&gt;&gt;&gt; tensor_on_cpu = to_cpu(tensor)\n</code></pre>"},{"location":"utils/data/#cmn_ai.utils.data.to_device","title":"<code>to_device(x, device=DEFAULT_DEVICE)</code>","text":"<p>Copy tensor(s) to specified device.</p> <p>Recursively moves tensors and collections of tensors to the specified device. If a tensor is already on the target device, returns the tensor itself.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Tensor or Iterable[Tensor] or Mapping[str, Tensor]</code>)           \u2013            <p>Tensor or collection of tensors to move to device.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cuda' if available else 'cpu'</code> )           \u2013            <p>Device to copy the tensor(s) to.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor or Iterable[Tensor] or Mapping[str, Tensor]</code>           \u2013            <p>Copied tensor(s) on the specified device.</p> </li> </ul> Notes <p>This function may fail if iterables contain non-tensor objects that don't have a <code>.to()</code> method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tensor = torch.randn(3, 3)\n&gt;&gt;&gt; tensor_on_gpu = to_device(tensor, 'cuda')\n&gt;&gt;&gt; batch = {'input': tensor, 'target': tensor}\n&gt;&gt;&gt; batch_on_gpu = to_device(batch, 'cuda')\n</code></pre>"},{"location":"utils/processors/","title":"Processors","text":"<p>Data processors for deep learning pipelines.</p> <p>This module provides processor classes designed to transform data before it is fed into deep learning models. Processors implement common data preprocessing patterns such as tokenization, numericalization, and vocabulary management for text and other sequential data.</p> <p>The processors follow a consistent interface pattern:</p> <ol> <li>Initialize with configuration parameters</li> <li>Fit to training data to learn vocabulary/transformations</li> <li>Transform data to numerical representations</li> <li>Reverse transform (decode) numerical data back to original form</li> </ol> <p>All processors support:</p> <ul> <li>Vocabulary management with automatic building from training data</li> <li>Frequency filtering to remove low-frequency tokens below threshold</li> <li>Size limits to respect maximum vocabulary size constraints</li> <li>Reserved tokens for special tokens (padding, unknown, etc.)</li> <li>Immediate usability when processors have predefined vocabularies</li> <li>Modern typing with Python 3.10+ union syntax</li> </ul> <p>Classes:</p> <ul> <li> <code>Processor</code>           \u2013            <p>Base class for all processors. Defines the processor interface.</p> </li> <li> <code>NumericalizeProcessor</code>           \u2013            <p>Converts tokens to numerical indices using a learned vocabulary. Supports frequency filtering, vocabulary size limits, and reserved tokens. Can be initialized with a predefined vocabulary for immediate use.</p> </li> </ul> <p>Examples:</p> <p>Basic token numericalization workflow:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.utils.processors import NumericalizeProcessor\n&gt;&gt;&gt; processor = NumericalizeProcessor(min_freq=2, max_vocab=1000)\n&gt;&gt;&gt; training_data = [[\"hello\", \"world\"], [\"hello\", \"there\"], [\"world\", \"peace\"]]\n&gt;&gt;&gt; processor.fit(training_data)\n&gt;&gt;&gt; indices = processor.process([\"hello\", \"world\"])\n&gt;&gt;&gt; print(indices)\n[1, 2]\n&gt;&gt;&gt; tokens = processor.deprocess(indices)\n&gt;&gt;&gt; print(tokens)\n['hello', 'world']\n</code></pre> <p>Using a predefined vocabulary:</p> <pre><code>&gt;&gt;&gt; vocab = [\"&lt;unk&gt;\", \"&lt;pad&gt;\", \"hello\", \"world\", \"goodbye\"]\n&gt;&gt;&gt; processor = NumericalizeProcessor(vocab=vocab)\n&gt;&gt;&gt; indices = processor.process([\"hello\", \"world\"])\n&gt;&gt;&gt; print(indices)\n[2, 3]\n</code></pre> <p>Including reserved tokens in vocabulary:</p> <pre><code>&gt;&gt;&gt; processor = NumericalizeProcessor(\n...     max_vocab=100,\n...     min_freq=1,\n...     reserved_tokens=[\"&lt;pad&gt;\", \"&lt;eos&gt;\", \"&lt;sos&gt;\"]\n... )\n&gt;&gt;&gt; processor.fit(training_data)\n</code></pre> Notes <p>Processors include comprehensive error handling:</p> <ul> <li><code>ValueError</code> is raised when attempting to use unfitted processors</li> <li>Unknown tokens are gracefully handled (returns unk_token index)</li> <li>Out-of-bounds indices are gracefully handled (returns unk_token)</li> <li>Vocabulary size constraints are strictly enforced</li> </ul> <p>Implementation details:</p> <ul> <li>Vocabulary building respects both frequency thresholds and size limits</li> <li>Reserved tokens are prioritized over data tokens when space is limited</li> <li>The unk_token is always included and has the highest priority</li> <li>All processors use modern Python type hints with union syntax (|)</li> </ul> See Also <p>cmn_ai.utils.utils : Utility functions used by processors cmn_ai.text.data : Text data handling utilities</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor","title":"<code>NumericalizeProcessor</code>","text":"<p>               Bases: <code>Processor</code></p> <p>A processor that converts tokens to numerical indices and vice versa.</p> <p>This processor builds a vocabulary from input tokens and provides methods to convert between tokens and their corresponding numerical indices.</p> <p>Parameters:</p> <ul> <li> <code>vocab</code>               (<code>List[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Pre-defined vocabulary. If None, vocabulary will be built from input data.</p> </li> <li> <code>max_vocab</code>               (<code>int</code>, default:                   <code>60000</code> )           \u2013            <p>Maximum vocabulary size.</p> </li> <li> <code>min_freq</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>Minimum frequency threshold for tokens to be included in vocabulary.</p> </li> <li> <code>reserved_tokens</code>               (<code>str | List[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Reserved tokens to always include in vocabulary (e.g., special tokens).</p> </li> <li> <code>unk_token</code>               (<code>str</code>, default:                   <code>\"&lt;unk&gt;\"</code> )           \u2013            <p>Token to use for unknown/out-of-vocabulary items.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>vocab</code>               (<code>List[str]</code>)           \u2013            <p>The vocabulary list mapping indices to tokens.</p> </li> <li> <code>token_to_idx</code>               (<code>Dict[str, int]</code>)           \u2013            <p>Mapping from tokens to their indices.</p> </li> <li> <code>idx_to_token</code>               (<code>Dict[int, str]</code>)           \u2013            <p>Mapping from indices to their tokens.</p> </li> <li> <code>is_fitted</code>               (<code>bool</code>)           \u2013            <p>Whether the processor has been fitted with data.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; processor = NumericalizeProcessor(min_freq=1)\n&gt;&gt;&gt; tokens = [[\"hello\", \"world\"], [\"hello\", \"there\"]]\n&gt;&gt;&gt; indices = processor(tokens)\n&gt;&gt;&gt; processor.deprocess(indices[0])\n['hello', 'world']\n</code></pre>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.idx_to_token","title":"<code>idx_to_token</code>  <code>property</code>","text":"<p>Get the index-to-token mapping.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.is_fitted","title":"<code>is_fitted</code>  <code>property</code>","text":"<p>Check if the processor has been fitted.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.token_to_idx","title":"<code>token_to_idx</code>  <code>property</code>","text":"<p>Get the token-to-index mapping.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.unk","title":"<code>unk</code>  <code>property</code>","text":"<p>Alias for unk_idx for backward compatibility.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.unk_idx","title":"<code>unk_idx</code>  <code>property</code>","text":"<p>Get the index of the unknown token.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.__call__","title":"<code>__call__(items)</code>","text":"<p>Process a list of items, building vocabulary if needed.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>List[str | List[str]]</code>)           \u2013            <p>List of tokens or token sequences to process.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[int | List[int]]</code>           \u2013            <p>List of corresponding indices or index sequences.</p> </li> </ul>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.__getitem__","title":"<code>__getitem__(tokens)</code>","text":"<p>Get indices for tokens using bracket notation.</p> <p>Parameters:</p> <ul> <li> <code>tokens</code>               (<code>str | List[str]</code>)           \u2013            <p>Token or list of tokens.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int | List[int]</code>           \u2013            <p>Corresponding index or list of indices.</p> </li> </ul>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.__len__","title":"<code>__len__()</code>","text":"<p>Return the size of the vocabulary.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.deprocess","title":"<code>deprocess(indices)</code>","text":"<p>Convert indices back to tokens.</p> <p>Parameters:</p> <ul> <li> <code>indices</code>               (<code>int | List[int]</code>)           \u2013            <p>Index or list of indices to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str | List[str]</code>           \u2013            <p>Corresponding token or list of tokens.</p> </li> </ul>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.fit","title":"<code>fit(items)</code>","text":"<p>Fit the processor to the data without processing.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>List[str | List[str]]</code>)           \u2013            <p>Items to build vocabulary from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NumericalizeProcessor</code>           \u2013            <p>Self for method chaining.</p> </li> </ul>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.get_index","title":"<code>get_index(token)</code>","text":"<p>Get index for a given token.</p> <p>Parameters:</p> <ul> <li> <code>token</code>               (<code>str</code>)           \u2013            <p>Token to look up.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Corresponding index.</p> </li> </ul>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.get_token","title":"<code>get_token(idx)</code>","text":"<p>Get token for a given index.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>               (<code>int</code>)           \u2013            <p>Index to look up.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Corresponding token.</p> </li> </ul>"},{"location":"utils/processors/#cmn_ai.utils.processors.NumericalizeProcessor.process","title":"<code>process(items)</code>","text":"<p>Convert tokens to indices.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>str | List[str]</code>)           \u2013            <p>Token or list of tokens to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int | List[int]</code>           \u2013            <p>Corresponding index or list of indices.</p> </li> </ul>"},{"location":"utils/processors/#cmn_ai.utils.processors.Processor","title":"<code>Processor</code>","text":"<p>Base class for all processors.</p>"},{"location":"utils/utils/","title":"Utilities","text":"<p>Useful Python utilities for data manipulation, memory management, and system configuration.</p> <p>This module provides utility functions for common data science and machine learning tasks. It includes functions for type conversion, data processing, random seed management, memory cleanup, and print configuration.</p> <p>Functions:</p> <ul> <li> <code>listify : Convert any object into a list</code>             \u2013              </li> <li> <code>tuplify : Convert any object into a tuple</code>             \u2013              </li> <li> <code>setify : Convert any object into a set</code>             \u2013              </li> <li> <code>uniqueify : Return a list of unique elements from an iterable</code>             \u2013              </li> <li> <code>set_seed : Set random seeds for reproducibility across multiple libraries</code>             \u2013              </li> <li> <code>clean_memory : Perform comprehensive memory cleanup</code>             \u2013              </li> <li> <code>clean_traceback : Clean memory used by traceback objects</code>             \u2013              </li> <li> <code>clean_ipython_history : Clean IPython command history to free memory</code>             \u2013              </li> <li> <code>set_printoptions : Set print options for NumPy and PyTorch</code>             \u2013              </li> </ul> Notes <p>This module is designed to work with PyTorch and NumPy, providing utilities that are commonly needed in machine learning workflows. The memory cleanup functions are particularly useful when working with large tensors on GPU.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.utils.utils import listify, set_seed, clean_memory\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Type conversion\n&gt;&gt;&gt; listify([1, 2, 3])\n[1, 2, 3]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Set random seed for reproducibility\n&gt;&gt;&gt; set_seed(42)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Clean memory after heavy computations\n&gt;&gt;&gt; clean_memory()\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.clean_ipython_history","title":"<code>clean_ipython_history()</code>","text":"<p>Clean IPython command history to free memory.</p> <p>This function clears the IPython history, which is particularly useful when working with large tensors or objects that consume significant memory. The implementation is based on IPython source code.</p> Notes <p>This function only works when running in an IPython environment. If not in IPython, the function returns without doing anything.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; clean_ipython_history()  # Clears history if in IPython\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.clean_memory","title":"<code>clean_memory()</code>","text":"<p>Perform comprehensive memory cleanup.</p> <p>This function performs a complete memory cleanup by: 1. Cleaning traceback objects 2. Clearing IPython history 3. Running garbage collection 4. Emptying PyTorch's CUDA cache</p> Notes <p>This is a comprehensive cleanup function that should be called when experiencing memory issues, especially when working with large tensors on GPU.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; clean_memory()  # Perform complete memory cleanup\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.clean_traceback","title":"<code>clean_traceback()</code>","text":"<p>Clean memory used by traceback objects.</p> <p>This function clears traceback objects that may hold references to large tensors or objects, preventing them from being garbage collected. This is particularly useful when dealing with GPU memory issues after exceptions.</p> Notes <p>When exceptions occur with large tensors, the traceback may keep references to these tensors in GPU memory, leading to out-of-memory errors even after attempting to clear GPU cache.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; try:\n...     # Some operation that might fail\n...     pass\n... except Exception:\n...     clean_traceback()  # Clean up traceback memory\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.listify","title":"<code>listify(obj)</code>","text":"<p>Convert any object into a list.</p> <p>This function handles various input types and converts them to a list format. None values are converted to empty lists, strings are wrapped in a list, and iterables are converted to lists.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>               (<code>Any</code>)           \u2013            <p>Object to convert into a list. Can be None, a string, an iterable, or any other object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>List representation of the input object.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; listify(None)\n[]\n&gt;&gt;&gt; listify(\"hello\")\n['hello']\n&gt;&gt;&gt; listify([1, 2, 3])\n[1, 2, 3]\n&gt;&gt;&gt; listify((1, 2, 3))\n[1, 2, 3]\n&gt;&gt;&gt; listify(42)\n[42]\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.set_printoptions","title":"<code>set_printoptions(precision=2, linewidth=125, sci_mode=False)</code>","text":"<p>Set print options for NumPy and PyTorch.</p> <p>This function configures the display format for both NumPy arrays and PyTorch tensors to ensure consistent output formatting.</p> <p>Parameters:</p> <ul> <li> <code>precision</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>Number of decimal digits to display for floating point numbers.</p> </li> <li> <code>linewidth</code>               (<code>int</code>, default:                   <code>125</code> )           \u2013            <p>Maximum number of characters per line before wrapping.</p> </li> <li> <code>sci_mode</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use scientific notation for floating point numbers. When True, numbers are displayed in scientific notation (e.g., 1e-3).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; set_printoptions(precision=4, linewidth=80)\n&gt;&gt;&gt; set_printoptions(precision=3, sci_mode=True)\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.set_seed","title":"<code>set_seed(seed=42, deterministic=False)</code>","text":"<p>Set random seeds for reproducibility across multiple libraries.</p> <p>This function sets the random seed for PyTorch, NumPy, and Python's random module to ensure reproducible results across runs.</p> <p>Parameters:</p> <ul> <li> <code>seed</code>               (<code>int</code>, default:                   <code>42</code> )           \u2013            <p>Random seed value to use for all random number generators.</p> </li> <li> <code>deterministic</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether PyTorch should use deterministic algorithms. When True, this may impact performance but ensures reproducibility.</p> </li> </ul> Notes <p>Setting deterministic=True in PyTorch may significantly slow down some operations, especially on GPU. Use only when absolute reproducibility is required.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; set_seed(42)\n&gt;&gt;&gt; set_seed(123, deterministic=True)\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.setify","title":"<code>setify(obj)</code>","text":"<p>Convert any object into a set.</p> <p>This function converts various input types to a set format by first converting to a list using listify, then converting to a set.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>               (<code>Any</code>)           \u2013            <p>Object to convert into a set. Can be None, a string, an iterable, or any other object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set</code>           \u2013            <p>Set representation of the input object.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; setify(None)\nset()\n&gt;&gt;&gt; setify(\"hello\")\n{'hello'}\n&gt;&gt;&gt; setify([1, 2, 2, 3])\n{1, 2, 3}\n&gt;&gt;&gt; setify({1, 2, 3})\n{1, 2, 3}\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.tuplify","title":"<code>tuplify(obj)</code>","text":"<p>Convert any object into a tuple.</p> <p>This function converts various input types to a tuple format by first converting to a list using listify, then converting to a tuple.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>               (<code>Any</code>)           \u2013            <p>Object to convert into a tuple. Can be None, a string, an iterable, or any other object.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>           \u2013            <p>Tuple representation of the input object.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tuplify(None)\n()\n&gt;&gt;&gt; tuplify(\"hello\")\n('hello',)\n&gt;&gt;&gt; tuplify([1, 2, 3])\n(1, 2, 3)\n&gt;&gt;&gt; tuplify((1, 2, 3))\n(1, 2, 3)\n</code></pre>"},{"location":"utils/utils/#cmn_ai.utils.utils.uniqueify","title":"<code>uniqueify(x, sort=False)</code>","text":"<p>Return a list of unique elements from an iterable.</p> <p>This function removes duplicates from an iterable and optionally sorts the resulting list.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>Iterable</code>)           \u2013            <p>Iterable to extract unique elements from.</p> </li> <li> <code>sort</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to sort the unique elements in ascending order.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>List containing unique elements from the input iterable.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; uniqueify([1, 2, 2, 3, 1])\n[1, 2, 3]\n&gt;&gt;&gt; uniqueify([3, 1, 2, 2, 1], sort=True)\n[1, 2, 3]\n&gt;&gt;&gt; uniqueify(\"hello\")\n['h', 'e', 'l', 'o']\n</code></pre>"},{"location":"vision/core/","title":"Core","text":"<p>Core vision functionality for computer vision tasks.</p> <p>This module provides specialized learners and utilities for computer vision tasks. It extends the base Learner class with vision-specific functionality such as batch visualization and image processing capabilities.</p> <p>Classes:</p> <ul> <li> <code>VisionLearner : Learner</code>           \u2013            <p>Learner specialized for computer vision tasks with batch visualization.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create a vision learner\n&gt;&gt;&gt; learner = VisionLearner(model, dls, loss_func, opt_func)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Show a batch of images\n&gt;&gt;&gt; learner.show_batch(sample_sz=4, figsize=(12, 8))\n</code></pre>"},{"location":"vision/core/#cmn_ai.vision.core.VisionLearner","title":"<code>VisionLearner</code>","text":"<p>               Bases: <code>Learner</code></p> <p>Learner specialized for computer vision tasks.</p> <p>This class extends the base Learner with vision-specific functionality, particularly for visualizing batches of images during training and inference. It provides convenient methods for displaying image data and monitoring training progress in computer vision applications.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create a vision learner with a CNN model\n&gt;&gt;&gt; model = torchvision.models.resnet18(pretrained=True)\n&gt;&gt;&gt; learner = VisionLearner(model, dls, loss_func, opt_func)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Show a batch of images\n&gt;&gt;&gt; learner.show_batch(sample_sz=4)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Train the model\n&gt;&gt;&gt; learner.fit_one_cycle(10)\n</code></pre>"},{"location":"vision/core/#cmn_ai.vision.core.VisionLearner.show_batch","title":"<code>show_batch(sample_sz=1, callbacks=None, **kwargs)</code>","text":"<p>Show a batch of images for visualization.</p> <p>This method runs a single forward pass through the model and displays the input images. It's useful for inspecting the data being fed to the model and verifying data preprocessing.</p> <p>Parameters:</p> <ul> <li> <code>sample_sz</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of input samples to show from the batch.</p> </li> <li> <code>callbacks</code>               (<code>Iterable[Callback] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional callbacks to add temporarily for this visualization. These callbacks will be removed after the method completes.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional keyword arguments passed to <code>show_images</code> function. Common options include: - figsize : tuple, default=(10, 10)     Figure size in inches (width, height) - nrows : int, default=None     Number of rows in the grid - ncols : int, default=None     Number of columns in the grid - title : str, default=None     Title for the figure - cmap : str, default=None     Colormap for grayscale images</p> </li> </ul> Notes <p>This method temporarily adds a <code>SingleBatchForwardCallback</code> to ensure only one batch is processed, regardless of the current training state. The method will automatically clean up any additional callbacks that were passed in.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Show 4 images from the current batch\n&gt;&gt;&gt; learner.show_batch(sample_sz=4, figsize=(12, 8))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Show images with custom grid layout\n&gt;&gt;&gt; learner.show_batch(sample_sz=9, nrows=3, ncols=3)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Show images with a title\n&gt;&gt;&gt; learner.show_batch(sample_sz=2, title=\"Training Batch\")\n</code></pre>"},{"location":"vision/data/","title":"Data","text":"<p>Vision data utilities for image processing and dataset management.</p> <p>This module provides utilities for working with image data in machine learning pipelines. It includes classes and functions for loading, managing, and processing image datasets with support for various image formats and transformations.</p> <p>The module is designed to work seamlessly with PIL (Python Imaging Library) and integrates with the broader cmn_ai data processing pipeline.</p> <p>Functions:</p> <ul> <li> <code>None</code>             \u2013              </li> </ul> <p>Classes:</p> <ul> <li> <code>ImageList : Image dataset container for managing collections of image files</code>           \u2013            </li> </ul> Constants <p>IMAGE_EXTENSIONS : list of str     List of supported image file extensions derived from mimetypes.</p> Notes <p>This module extends the base data utilities to provide vision-specific functionality for image processing workflows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cmn_ai.vision.data import ImageList\n&gt;&gt;&gt; # Create image dataset from directory\n&gt;&gt;&gt; images = ImageList.from_files('./data/images')\n&gt;&gt;&gt; # Access first image\n&gt;&gt;&gt; img = images[0]  # Returns PIL.Image object\n&gt;&gt;&gt; print(img.size)  # (width, height)\n</code></pre>"},{"location":"vision/data/#cmn_ai.vision.data.ImageList","title":"<code>ImageList</code>","text":"<p>               Bases: <code>ItemList</code></p> <p>Image dataset container for managing collections of image files.</p> <p>A specialized ItemList subclass for handling image datasets. It provides functionality to load and manage collections of image files with support for various image formats, transformations, and file discovery.</p> <p>Attributes:</p> <ul> <li> <code>path</code>               (<code>Path</code>)           \u2013            <p>Base path where the image files are located.</p> </li> <li> <code>tfms</code>               (<code>(callable, optional)</code>)           \u2013            <p>Transformations to apply to images when retrieved.</p> </li> <li> <code>data</code>               (<code>list[Path]</code>)           \u2013            <p>List of image file paths.</p> </li> </ul> Notes <p>This class extends ItemList to provide image-specific functionality. Images are loaded using PIL (Python Imaging Library) when accessed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create ImageList from a directory\n&gt;&gt;&gt; image_list = ImageList.from_files('./data/images')\n&gt;&gt;&gt; # Access first image\n&gt;&gt;&gt; img = image_list[0]  # Returns PIL.Image object\n&gt;&gt;&gt; # Create with transformations\n&gt;&gt;&gt; from torchvision import transforms\n&gt;&gt;&gt; tfms = transforms.Compose([transforms.Resize((224, 224))])\n&gt;&gt;&gt; image_list = ImageList.from_files('./data', tfms=tfms)\n</code></pre>"},{"location":"vision/data/#cmn_ai.vision.data.ImageList.from_files","title":"<code>from_files(path, extensions=IMAGE_EXTENSIONS, include=None, recurse=True, tfms=None)</code>  <code>classmethod</code>","text":"<p>Create an ImageList from files in a directory.</p> <p>Factory method to create an ImageList by discovering image files in the specified directory. Supports various image formats and recursive directory traversal.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str or Path</code>)           \u2013            <p>Path for the root directory to search for image files.</p> </li> <li> <code>extensions</code>               (<code>str or iterable of str</code>, default:                   <code>IMAGE_EXTENSIONS</code> )           \u2013            <p>File extensions to include. Defaults to all supported image formats.</p> </li> <li> <code>include</code>               (<code>iterable of str</code>, default:                   <code>None</code> )           \u2013            <p>Top-level directory(ies) under <code>path</code> to use for searching files. If None, searches all directories.</p> </li> <li> <code>recurse</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to search subdirectories recursively.</p> </li> <li> <code>tfms</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>Transformations to apply to images before returning them.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ImageList</code>           \u2013            <p>New ImageList instance containing discovered image files.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create from directory with default settings\n&gt;&gt;&gt; images = ImageList.from_files('./data/images')\n&gt;&gt;&gt; # Create with specific extensions\n&gt;&gt;&gt; images = ImageList.from_files('./data', extensions=['.jpg', '.png'])\n&gt;&gt;&gt; # Create without recursion\n&gt;&gt;&gt; images = ImageList.from_files('./data', recurse=False)\n</code></pre>"},{"location":"vision/data/#cmn_ai.vision.data.ImageList.get","title":"<code>get(item)</code>","text":"<p>Load and return an image from file path.</p> <p>Opens an image file using PIL and returns the PIL Image object. This method is called automatically when accessing items from the ImageList.</p> <p>Parameters:</p> <ul> <li> <code>item</code>               (<code>Path</code>)           \u2013            <p>File path to the image to load.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Image</code>           \u2013            <p>Loaded image object.</p> </li> </ul> Notes <p>The image is loaded in its original format. If transformations are specified in the ImageList, they will be applied after loading.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; image_list = ImageList.from_files('./data')\n&gt;&gt;&gt; img = image_list.get(Path('./data/image.jpg'))\n&gt;&gt;&gt; print(img.size)  # (width, height)\n</code></pre>"}]}